<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="Asciidoctor 2.0.10">
<title>Deploying and Managing OpenShift Container Storage</title>
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:300,300italic,400,400italic,600,600italic%7CNoto+Serif:400,400italic,700,700italic%7CDroid+Sans+Mono:400,700">
<style>
/* Asciidoctor default stylesheet | MIT License | https://asciidoctor.org */
/* Uncomment @import statement to use as custom stylesheet */
/*@import "https://fonts.googleapis.com/css?family=Open+Sans:300,300italic,400,400italic,600,600italic%7CNoto+Serif:400,400italic,700,700italic%7CDroid+Sans+Mono:400,700";*/
article,aside,details,figcaption,figure,footer,header,hgroup,main,nav,section{display:block}
audio,video{display:inline-block}
audio:not([controls]){display:none;height:0}
html{font-family:sans-serif;-ms-text-size-adjust:100%;-webkit-text-size-adjust:100%}
a{background:none}
a:focus{outline:thin dotted}
a:active,a:hover{outline:0}
h1{font-size:2em;margin:.67em 0}
abbr[title]{border-bottom:1px dotted}
b,strong{font-weight:bold}
dfn{font-style:italic}
hr{-moz-box-sizing:content-box;box-sizing:content-box;height:0}
mark{background:#ff0;color:#000}
code,kbd,pre,samp{font-family:monospace;font-size:1em}
pre{white-space:pre-wrap}
q{quotes:"\201C" "\201D" "\2018" "\2019"}
small{font-size:80%}
sub,sup{font-size:75%;line-height:0;position:relative;vertical-align:baseline}
sup{top:-.5em}
sub{bottom:-.25em}
img{border:0}
svg:not(:root){overflow:hidden}
figure{margin:0}
fieldset{border:1px solid silver;margin:0 2px;padding:.35em .625em .75em}
legend{border:0;padding:0}
button,input,select,textarea{font-family:inherit;font-size:100%;margin:0}
button,input{line-height:normal}
button,select{text-transform:none}
button,html input[type="button"],input[type="reset"],input[type="submit"]{-webkit-appearance:button;cursor:pointer}
button[disabled],html input[disabled]{cursor:default}
input[type="checkbox"],input[type="radio"]{box-sizing:border-box;padding:0}
button::-moz-focus-inner,input::-moz-focus-inner{border:0;padding:0}
textarea{overflow:auto;vertical-align:top}
table{border-collapse:collapse;border-spacing:0}
*,*::before,*::after{-moz-box-sizing:border-box;-webkit-box-sizing:border-box;box-sizing:border-box}
html,body{font-size:100%}
body{background:#fff;color:rgba(0,0,0,.8);padding:0;margin:0;font-family:"Noto Serif","DejaVu Serif",serif;font-weight:400;font-style:normal;line-height:1;position:relative;cursor:auto;tab-size:4;-moz-osx-font-smoothing:grayscale;-webkit-font-smoothing:antialiased}
a:hover{cursor:pointer}
img,object,embed{max-width:100%;height:auto}
object,embed{height:100%}
img{-ms-interpolation-mode:bicubic}
.left{float:left!important}
.right{float:right!important}
.text-left{text-align:left!important}
.text-right{text-align:right!important}
.text-center{text-align:center!important}
.text-justify{text-align:justify!important}
.hide{display:none}
img,object,svg{display:inline-block;vertical-align:middle}
textarea{height:auto;min-height:50px}
select{width:100%}
.center{margin-left:auto;margin-right:auto}
.stretch{width:100%}
.subheader,.admonitionblock td.content>.title,.audioblock>.title,.exampleblock>.title,.imageblock>.title,.listingblock>.title,.literalblock>.title,.stemblock>.title,.openblock>.title,.paragraph>.title,.quoteblock>.title,table.tableblock>.title,.verseblock>.title,.videoblock>.title,.dlist>.title,.olist>.title,.ulist>.title,.qlist>.title,.hdlist>.title{line-height:1.45;color:#7a2518;font-weight:400;margin-top:0;margin-bottom:.25em}
div,dl,dt,dd,ul,ol,li,h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6,pre,form,p,blockquote,th,td{margin:0;padding:0;direction:ltr}
a{color:#2156a5;text-decoration:underline;line-height:inherit}
a:hover,a:focus{color:#1d4b8f}
a img{border:0}
p{font-family:inherit;font-weight:400;font-size:1em;line-height:1.6;margin-bottom:1.25em;text-rendering:optimizeLegibility}
p aside{font-size:.875em;line-height:1.35;font-style:italic}
h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{font-family:"Open Sans","DejaVu Sans",sans-serif;font-weight:300;font-style:normal;color:#ba3925;text-rendering:optimizeLegibility;margin-top:1em;margin-bottom:.5em;line-height:1.0125em}
h1 small,h2 small,h3 small,#toctitle small,.sidebarblock>.content>.title small,h4 small,h5 small,h6 small{font-size:60%;color:#e99b8f;line-height:0}
h1{font-size:2.125em}
h2{font-size:1.6875em}
h3,#toctitle,.sidebarblock>.content>.title{font-size:1.375em}
h4,h5{font-size:1.125em}
h6{font-size:1em}
hr{border:solid #dddddf;border-width:1px 0 0;clear:both;margin:1.25em 0 1.1875em;height:0}
em,i{font-style:italic;line-height:inherit}
strong,b{font-weight:bold;line-height:inherit}
small{font-size:60%;line-height:inherit}
code{font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;font-weight:400;color:rgba(0,0,0,.9)}
ul,ol,dl{font-size:1em;line-height:1.6;margin-bottom:1.25em;list-style-position:outside;font-family:inherit}
ul,ol{margin-left:1.5em}
ul li ul,ul li ol{margin-left:1.25em;margin-bottom:0;font-size:1em}
ul.square li ul,ul.circle li ul,ul.disc li ul{list-style:inherit}
ul.square{list-style-type:square}
ul.circle{list-style-type:circle}
ul.disc{list-style-type:disc}
ol li ul,ol li ol{margin-left:1.25em;margin-bottom:0}
dl dt{margin-bottom:.3125em;font-weight:bold}
dl dd{margin-bottom:1.25em}
abbr,acronym{text-transform:uppercase;font-size:90%;color:rgba(0,0,0,.8);border-bottom:1px dotted #ddd;cursor:help}
abbr{text-transform:none}
blockquote{margin:0 0 1.25em;padding:.5625em 1.25em 0 1.1875em;border-left:1px solid #ddd}
blockquote cite{display:block;font-size:.9375em;color:rgba(0,0,0,.6)}
blockquote cite::before{content:"\2014 \0020"}
blockquote cite a,blockquote cite a:visited{color:rgba(0,0,0,.6)}
blockquote,blockquote p{line-height:1.6;color:rgba(0,0,0,.85)}
@media screen and (min-width:768px){h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{line-height:1.2}
h1{font-size:2.75em}
h2{font-size:2.3125em}
h3,#toctitle,.sidebarblock>.content>.title{font-size:1.6875em}
h4{font-size:1.4375em}}
table{background:#fff;margin-bottom:1.25em;border:solid 1px #dedede}
table thead,table tfoot{background:#f7f8f7}
table thead tr th,table thead tr td,table tfoot tr th,table tfoot tr td{padding:.5em .625em .625em;font-size:inherit;color:rgba(0,0,0,.8);text-align:left}
table tr th,table tr td{padding:.5625em .625em;font-size:inherit;color:rgba(0,0,0,.8)}
table tr.even,table tr.alt{background:#f8f8f7}
table thead tr th,table tfoot tr th,table tbody tr td,table tr td,table tfoot tr td{display:table-cell;line-height:1.6}
h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{line-height:1.2;word-spacing:-.05em}
h1 strong,h2 strong,h3 strong,#toctitle strong,.sidebarblock>.content>.title strong,h4 strong,h5 strong,h6 strong{font-weight:400}
.clearfix::before,.clearfix::after,.float-group::before,.float-group::after{content:" ";display:table}
.clearfix::after,.float-group::after{clear:both}
:not(pre):not([class^=L])>code{font-size:.9375em;font-style:normal!important;letter-spacing:0;padding:.1em .5ex;word-spacing:-.15em;background:#f7f7f8;-webkit-border-radius:4px;border-radius:4px;line-height:1.45;text-rendering:optimizeSpeed;word-wrap:break-word}
:not(pre)>code.nobreak{word-wrap:normal}
:not(pre)>code.nowrap{white-space:nowrap}
pre{color:rgba(0,0,0,.9);font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;line-height:1.45;text-rendering:optimizeSpeed}
pre code,pre pre{color:inherit;font-size:inherit;line-height:inherit}
pre>code{display:block}
pre.nowrap,pre.nowrap pre{white-space:pre;word-wrap:normal}
em em{font-style:normal}
strong strong{font-weight:400}
.keyseq{color:rgba(51,51,51,.8)}
kbd{font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;display:inline-block;color:rgba(0,0,0,.8);font-size:.65em;line-height:1.45;background:#f7f7f7;border:1px solid #ccc;-webkit-border-radius:3px;border-radius:3px;-webkit-box-shadow:0 1px 0 rgba(0,0,0,.2),0 0 0 .1em white inset;box-shadow:0 1px 0 rgba(0,0,0,.2),0 0 0 .1em #fff inset;margin:0 .15em;padding:.2em .5em;vertical-align:middle;position:relative;top:-.1em;white-space:nowrap}
.keyseq kbd:first-child{margin-left:0}
.keyseq kbd:last-child{margin-right:0}
.menuseq,.menuref{color:#000}
.menuseq b:not(.caret),.menuref{font-weight:inherit}
.menuseq{word-spacing:-.02em}
.menuseq b.caret{font-size:1.25em;line-height:.8}
.menuseq i.caret{font-weight:bold;text-align:center;width:.45em}
b.button::before,b.button::after{position:relative;top:-1px;font-weight:400}
b.button::before{content:"[";padding:0 3px 0 2px}
b.button::after{content:"]";padding:0 2px 0 3px}
p a>code:hover{color:rgba(0,0,0,.9)}
#header,#content,#footnotes,#footer{width:100%;margin-left:auto;margin-right:auto;margin-top:0;margin-bottom:0;max-width:62.5em;*zoom:1;position:relative;padding-left:.9375em;padding-right:.9375em}
#header::before,#header::after,#content::before,#content::after,#footnotes::before,#footnotes::after,#footer::before,#footer::after{content:" ";display:table}
#header::after,#content::after,#footnotes::after,#footer::after{clear:both}
#content{margin-top:1.25em}
#content::before{content:none}
#header>h1:first-child{color:rgba(0,0,0,.85);margin-top:2.25rem;margin-bottom:0}
#header>h1:first-child+#toc{margin-top:8px;border-top:1px solid #dddddf}
#header>h1:only-child,body.toc2 #header>h1:nth-last-child(2){border-bottom:1px solid #dddddf;padding-bottom:8px}
#header .details{border-bottom:1px solid #dddddf;line-height:1.45;padding-top:.25em;padding-bottom:.25em;padding-left:.25em;color:rgba(0,0,0,.6);display:-ms-flexbox;display:-webkit-flex;display:flex;-ms-flex-flow:row wrap;-webkit-flex-flow:row wrap;flex-flow:row wrap}
#header .details span:first-child{margin-left:-.125em}
#header .details span.email a{color:rgba(0,0,0,.85)}
#header .details br{display:none}
#header .details br+span::before{content:"\00a0\2013\00a0"}
#header .details br+span.author::before{content:"\00a0\22c5\00a0";color:rgba(0,0,0,.85)}
#header .details br+span#revremark::before{content:"\00a0|\00a0"}
#header #revnumber{text-transform:capitalize}
#header #revnumber::after{content:"\00a0"}
#content>h1:first-child:not([class]){color:rgba(0,0,0,.85);border-bottom:1px solid #dddddf;padding-bottom:8px;margin-top:0;padding-top:1rem;margin-bottom:1.25rem}
#toc{border-bottom:1px solid #e7e7e9;padding-bottom:.5em}
#toc>ul{margin-left:.125em}
#toc ul.sectlevel0>li>a{font-style:italic}
#toc ul.sectlevel0 ul.sectlevel1{margin:.5em 0}
#toc ul{font-family:"Open Sans","DejaVu Sans",sans-serif;list-style-type:none}
#toc li{line-height:1.3334;margin-top:.3334em}
#toc a{text-decoration:none}
#toc a:active{text-decoration:underline}
#toctitle{color:#7a2518;font-size:1.2em}
@media screen and (min-width:768px){#toctitle{font-size:1.375em}
body.toc2{padding-left:15em;padding-right:0}
#toc.toc2{margin-top:0!important;background:#f8f8f7;position:fixed;width:15em;left:0;top:0;border-right:1px solid #e7e7e9;border-top-width:0!important;border-bottom-width:0!important;z-index:1000;padding:1.25em 1em;height:100%;overflow:auto}
#toc.toc2 #toctitle{margin-top:0;margin-bottom:.8rem;font-size:1.2em}
#toc.toc2>ul{font-size:.9em;margin-bottom:0}
#toc.toc2 ul ul{margin-left:0;padding-left:1em}
#toc.toc2 ul.sectlevel0 ul.sectlevel1{padding-left:0;margin-top:.5em;margin-bottom:.5em}
body.toc2.toc-right{padding-left:0;padding-right:15em}
body.toc2.toc-right #toc.toc2{border-right-width:0;border-left:1px solid #e7e7e9;left:auto;right:0}}
@media screen and (min-width:1280px){body.toc2{padding-left:20em;padding-right:0}
#toc.toc2{width:20em}
#toc.toc2 #toctitle{font-size:1.375em}
#toc.toc2>ul{font-size:.95em}
#toc.toc2 ul ul{padding-left:1.25em}
body.toc2.toc-right{padding-left:0;padding-right:20em}}
#content #toc{border-style:solid;border-width:1px;border-color:#e0e0dc;margin-bottom:1.25em;padding:1.25em;background:#f8f8f7;-webkit-border-radius:4px;border-radius:4px}
#content #toc>:first-child{margin-top:0}
#content #toc>:last-child{margin-bottom:0}
#footer{max-width:100%;background:rgba(0,0,0,.8);padding:1.25em}
#footer-text{color:rgba(255,255,255,.8);line-height:1.44}
#content{margin-bottom:.625em}
.sect1{padding-bottom:.625em}
@media screen and (min-width:768px){#content{margin-bottom:1.25em}
.sect1{padding-bottom:1.25em}}
.sect1:last-child{padding-bottom:0}
.sect1+.sect1{border-top:1px solid #e7e7e9}
#content h1>a.anchor,h2>a.anchor,h3>a.anchor,#toctitle>a.anchor,.sidebarblock>.content>.title>a.anchor,h4>a.anchor,h5>a.anchor,h6>a.anchor{position:absolute;z-index:1001;width:1.5ex;margin-left:-1.5ex;display:block;text-decoration:none!important;visibility:hidden;text-align:center;font-weight:400}
#content h1>a.anchor::before,h2>a.anchor::before,h3>a.anchor::before,#toctitle>a.anchor::before,.sidebarblock>.content>.title>a.anchor::before,h4>a.anchor::before,h5>a.anchor::before,h6>a.anchor::before{content:"\00A7";font-size:.85em;display:block;padding-top:.1em}
#content h1:hover>a.anchor,#content h1>a.anchor:hover,h2:hover>a.anchor,h2>a.anchor:hover,h3:hover>a.anchor,#toctitle:hover>a.anchor,.sidebarblock>.content>.title:hover>a.anchor,h3>a.anchor:hover,#toctitle>a.anchor:hover,.sidebarblock>.content>.title>a.anchor:hover,h4:hover>a.anchor,h4>a.anchor:hover,h5:hover>a.anchor,h5>a.anchor:hover,h6:hover>a.anchor,h6>a.anchor:hover{visibility:visible}
#content h1>a.link,h2>a.link,h3>a.link,#toctitle>a.link,.sidebarblock>.content>.title>a.link,h4>a.link,h5>a.link,h6>a.link{color:#ba3925;text-decoration:none}
#content h1>a.link:hover,h2>a.link:hover,h3>a.link:hover,#toctitle>a.link:hover,.sidebarblock>.content>.title>a.link:hover,h4>a.link:hover,h5>a.link:hover,h6>a.link:hover{color:#a53221}
details,.audioblock,.imageblock,.literalblock,.listingblock,.stemblock,.videoblock{margin-bottom:1.25em}
details>summary:first-of-type{cursor:pointer;display:list-item;outline:none;margin-bottom:.75em}
.admonitionblock td.content>.title,.audioblock>.title,.exampleblock>.title,.imageblock>.title,.listingblock>.title,.literalblock>.title,.stemblock>.title,.openblock>.title,.paragraph>.title,.quoteblock>.title,table.tableblock>.title,.verseblock>.title,.videoblock>.title,.dlist>.title,.olist>.title,.ulist>.title,.qlist>.title,.hdlist>.title{text-rendering:optimizeLegibility;text-align:left;font-family:"Noto Serif","DejaVu Serif",serif;font-size:1rem;font-style:italic}
table.tableblock.fit-content>caption.title{white-space:nowrap;width:0}
.paragraph.lead>p,#preamble>.sectionbody>[class="paragraph"]:first-of-type p{font-size:1.21875em;line-height:1.6;color:rgba(0,0,0,.85)}
table.tableblock #preamble>.sectionbody>[class="paragraph"]:first-of-type p{font-size:inherit}
.admonitionblock>table{border-collapse:separate;border:0;background:none;width:100%}
.admonitionblock>table td.icon{text-align:center;width:80px}
.admonitionblock>table td.icon img{max-width:none}
.admonitionblock>table td.icon .title{font-weight:bold;font-family:"Open Sans","DejaVu Sans",sans-serif;text-transform:uppercase}
.admonitionblock>table td.content{padding-left:1.125em;padding-right:1.25em;border-left:1px solid #dddddf;color:rgba(0,0,0,.6)}
.admonitionblock>table td.content>:last-child>:last-child{margin-bottom:0}
.exampleblock>.content{border-style:solid;border-width:1px;border-color:#e6e6e6;margin-bottom:1.25em;padding:1.25em;background:#fff;-webkit-border-radius:4px;border-radius:4px}
.exampleblock>.content>:first-child{margin-top:0}
.exampleblock>.content>:last-child{margin-bottom:0}
.sidebarblock{border-style:solid;border-width:1px;border-color:#dbdbd6;margin-bottom:1.25em;padding:1.25em;background:#f3f3f2;-webkit-border-radius:4px;border-radius:4px}
.sidebarblock>:first-child{margin-top:0}
.sidebarblock>:last-child{margin-bottom:0}
.sidebarblock>.content>.title{color:#7a2518;margin-top:0;text-align:center}
.exampleblock>.content>:last-child>:last-child,.exampleblock>.content .olist>ol>li:last-child>:last-child,.exampleblock>.content .ulist>ul>li:last-child>:last-child,.exampleblock>.content .qlist>ol>li:last-child>:last-child,.sidebarblock>.content>:last-child>:last-child,.sidebarblock>.content .olist>ol>li:last-child>:last-child,.sidebarblock>.content .ulist>ul>li:last-child>:last-child,.sidebarblock>.content .qlist>ol>li:last-child>:last-child{margin-bottom:0}
.literalblock pre,.listingblock>.content>pre{-webkit-border-radius:4px;border-radius:4px;word-wrap:break-word;overflow-x:auto;padding:1em;font-size:.8125em}
@media screen and (min-width:768px){.literalblock pre,.listingblock>.content>pre{font-size:.90625em}}
@media screen and (min-width:1280px){.literalblock pre,.listingblock>.content>pre{font-size:1em}}
.literalblock pre,.listingblock>.content>pre:not(.highlight),.listingblock>.content>pre[class="highlight"],.listingblock>.content>pre[class^="highlight "]{background:#f7f7f8}
.literalblock.output pre{color:#f7f7f8;background:rgba(0,0,0,.9)}
.listingblock>.content{position:relative}
.listingblock code[data-lang]::before{display:none;content:attr(data-lang);position:absolute;font-size:.75em;top:.425rem;right:.5rem;line-height:1;text-transform:uppercase;color:inherit;opacity:.5}
.listingblock:hover code[data-lang]::before{display:block}
.listingblock.terminal pre .command::before{content:attr(data-prompt);padding-right:.5em;color:inherit;opacity:.5}
.listingblock.terminal pre .command:not([data-prompt])::before{content:"$"}
.listingblock pre.highlightjs{padding:0}
.listingblock pre.highlightjs>code{padding:1em;-webkit-border-radius:4px;border-radius:4px}
.listingblock pre.prettyprint{border-width:0}
.prettyprint{background:#f7f7f8}
pre.prettyprint .linenums{line-height:1.45;margin-left:2em}
pre.prettyprint li{background:none;list-style-type:inherit;padding-left:0}
pre.prettyprint li code[data-lang]::before{opacity:1}
pre.prettyprint li:not(:first-child) code[data-lang]::before{display:none}
table.linenotable{border-collapse:separate;border:0;margin-bottom:0;background:none}
table.linenotable td[class]{color:inherit;vertical-align:top;padding:0;line-height:inherit;white-space:normal}
table.linenotable td.code{padding-left:.75em}
table.linenotable td.linenos{border-right:1px solid currentColor;opacity:.35;padding-right:.5em}
pre.pygments .lineno{border-right:1px solid currentColor;opacity:.35;display:inline-block;margin-right:.75em}
pre.pygments .lineno::before{content:"";margin-right:-.125em}
.quoteblock{margin:0 1em 1.25em 1.5em;display:table}
.quoteblock:not(.excerpt)>.title{margin-left:-1.5em;margin-bottom:.75em}
.quoteblock blockquote,.quoteblock p{color:rgba(0,0,0,.85);font-size:1.15rem;line-height:1.75;word-spacing:.1em;letter-spacing:0;font-style:italic;text-align:justify}
.quoteblock blockquote{margin:0;padding:0;border:0}
.quoteblock blockquote::before{content:"\201c";float:left;font-size:2.75em;font-weight:bold;line-height:.6em;margin-left:-.6em;color:#7a2518;text-shadow:0 1px 2px rgba(0,0,0,.1)}
.quoteblock blockquote>.paragraph:last-child p{margin-bottom:0}
.quoteblock .attribution{margin-top:.75em;margin-right:.5ex;text-align:right}
.verseblock{margin:0 1em 1.25em}
.verseblock pre{font-family:"Open Sans","DejaVu Sans",sans;font-size:1.15rem;color:rgba(0,0,0,.85);font-weight:300;text-rendering:optimizeLegibility}
.verseblock pre strong{font-weight:400}
.verseblock .attribution{margin-top:1.25rem;margin-left:.5ex}
.quoteblock .attribution,.verseblock .attribution{font-size:.9375em;line-height:1.45;font-style:italic}
.quoteblock .attribution br,.verseblock .attribution br{display:none}
.quoteblock .attribution cite,.verseblock .attribution cite{display:block;letter-spacing:-.025em;color:rgba(0,0,0,.6)}
.quoteblock.abstract blockquote::before,.quoteblock.excerpt blockquote::before,.quoteblock .quoteblock blockquote::before{display:none}
.quoteblock.abstract blockquote,.quoteblock.abstract p,.quoteblock.excerpt blockquote,.quoteblock.excerpt p,.quoteblock .quoteblock blockquote,.quoteblock .quoteblock p{line-height:1.6;word-spacing:0}
.quoteblock.abstract{margin:0 1em 1.25em;display:block}
.quoteblock.abstract>.title{margin:0 0 .375em;font-size:1.15em;text-align:center}
.quoteblock.excerpt>blockquote,.quoteblock .quoteblock{padding:0 0 .25em 1em;border-left:.25em solid #dddddf}
.quoteblock.excerpt,.quoteblock .quoteblock{margin-left:0}
.quoteblock.excerpt blockquote,.quoteblock.excerpt p,.quoteblock .quoteblock blockquote,.quoteblock .quoteblock p{color:inherit;font-size:1.0625rem}
.quoteblock.excerpt .attribution,.quoteblock .quoteblock .attribution{color:inherit;text-align:left;margin-right:0}
table.tableblock{max-width:100%;border-collapse:separate}
p.tableblock:last-child{margin-bottom:0}
td.tableblock>.content>:last-child{margin-bottom:-1.25em}
td.tableblock>.content>:last-child.sidebarblock{margin-bottom:0}
table.tableblock,th.tableblock,td.tableblock{border:0 solid #dedede}
table.grid-all>thead>tr>.tableblock,table.grid-all>tbody>tr>.tableblock{border-width:0 1px 1px 0}
table.grid-all>tfoot>tr>.tableblock{border-width:1px 1px 0 0}
table.grid-cols>*>tr>.tableblock{border-width:0 1px 0 0}
table.grid-rows>thead>tr>.tableblock,table.grid-rows>tbody>tr>.tableblock{border-width:0 0 1px}
table.grid-rows>tfoot>tr>.tableblock{border-width:1px 0 0}
table.grid-all>*>tr>.tableblock:last-child,table.grid-cols>*>tr>.tableblock:last-child{border-right-width:0}
table.grid-all>tbody>tr:last-child>.tableblock,table.grid-all>thead:last-child>tr>.tableblock,table.grid-rows>tbody>tr:last-child>.tableblock,table.grid-rows>thead:last-child>tr>.tableblock{border-bottom-width:0}
table.frame-all{border-width:1px}
table.frame-sides{border-width:0 1px}
table.frame-topbot,table.frame-ends{border-width:1px 0}
table.stripes-all tr,table.stripes-odd tr:nth-of-type(odd),table.stripes-even tr:nth-of-type(even),table.stripes-hover tr:hover{background:#f8f8f7}
th.halign-left,td.halign-left{text-align:left}
th.halign-right,td.halign-right{text-align:right}
th.halign-center,td.halign-center{text-align:center}
th.valign-top,td.valign-top{vertical-align:top}
th.valign-bottom,td.valign-bottom{vertical-align:bottom}
th.valign-middle,td.valign-middle{vertical-align:middle}
table thead th,table tfoot th{font-weight:bold}
tbody tr th{display:table-cell;line-height:1.6;background:#f7f8f7}
tbody tr th,tbody tr th p,tfoot tr th,tfoot tr th p{color:rgba(0,0,0,.8);font-weight:bold}
p.tableblock>code:only-child{background:none;padding:0}
p.tableblock{font-size:1em}
ol{margin-left:1.75em}
ul li ol{margin-left:1.5em}
dl dd{margin-left:1.125em}
dl dd:last-child,dl dd:last-child>:last-child{margin-bottom:0}
ol>li p,ul>li p,ul dd,ol dd,.olist .olist,.ulist .ulist,.ulist .olist,.olist .ulist{margin-bottom:.625em}
ul.checklist,ul.none,ol.none,ul.no-bullet,ol.no-bullet,ol.unnumbered,ul.unstyled,ol.unstyled{list-style-type:none}
ul.no-bullet,ol.no-bullet,ol.unnumbered{margin-left:.625em}
ul.unstyled,ol.unstyled{margin-left:0}
ul.checklist{margin-left:.625em}
ul.checklist li>p:first-child>.fa-square-o:first-child,ul.checklist li>p:first-child>.fa-check-square-o:first-child{width:1.25em;font-size:.8em;position:relative;bottom:.125em}
ul.checklist li>p:first-child>input[type="checkbox"]:first-child{margin-right:.25em}
ul.inline{display:-ms-flexbox;display:-webkit-box;display:flex;-ms-flex-flow:row wrap;-webkit-flex-flow:row wrap;flex-flow:row wrap;list-style:none;margin:0 0 .625em -1.25em}
ul.inline>li{margin-left:1.25em}
.unstyled dl dt{font-weight:400;font-style:normal}
ol.arabic{list-style-type:decimal}
ol.decimal{list-style-type:decimal-leading-zero}
ol.loweralpha{list-style-type:lower-alpha}
ol.upperalpha{list-style-type:upper-alpha}
ol.lowerroman{list-style-type:lower-roman}
ol.upperroman{list-style-type:upper-roman}
ol.lowergreek{list-style-type:lower-greek}
.hdlist>table,.colist>table{border:0;background:none}
.hdlist>table>tbody>tr,.colist>table>tbody>tr{background:none}
td.hdlist1,td.hdlist2{vertical-align:top;padding:0 .625em}
td.hdlist1{font-weight:bold;padding-bottom:1.25em}
.literalblock+.colist,.listingblock+.colist{margin-top:-.5em}
.colist td:not([class]):first-child{padding:.4em .75em 0;line-height:1;vertical-align:top}
.colist td:not([class]):first-child img{max-width:none}
.colist td:not([class]):last-child{padding:.25em 0}
.thumb,.th{line-height:0;display:inline-block;border:solid 4px #fff;-webkit-box-shadow:0 0 0 1px #ddd;box-shadow:0 0 0 1px #ddd}
.imageblock.left{margin:.25em .625em 1.25em 0}
.imageblock.right{margin:.25em 0 1.25em .625em}
.imageblock>.title{margin-bottom:0}
.imageblock.thumb,.imageblock.th{border-width:6px}
.imageblock.thumb>.title,.imageblock.th>.title{padding:0 .125em}
.image.left,.image.right{margin-top:.25em;margin-bottom:.25em;display:inline-block;line-height:0}
.image.left{margin-right:.625em}
.image.right{margin-left:.625em}
a.image{text-decoration:none;display:inline-block}
a.image object{pointer-events:none}
sup.footnote,sup.footnoteref{font-size:.875em;position:static;vertical-align:super}
sup.footnote a,sup.footnoteref a{text-decoration:none}
sup.footnote a:active,sup.footnoteref a:active{text-decoration:underline}
#footnotes{padding-top:.75em;padding-bottom:.75em;margin-bottom:.625em}
#footnotes hr{width:20%;min-width:6.25em;margin:-.25em 0 .75em;border-width:1px 0 0}
#footnotes .footnote{padding:0 .375em 0 .225em;line-height:1.3334;font-size:.875em;margin-left:1.2em;margin-bottom:.2em}
#footnotes .footnote a:first-of-type{font-weight:bold;text-decoration:none;margin-left:-1.05em}
#footnotes .footnote:last-of-type{margin-bottom:0}
#content #footnotes{margin-top:-.625em;margin-bottom:0;padding:.75em 0}
.gist .file-data>table{border:0;background:#fff;width:100%;margin-bottom:0}
.gist .file-data>table td.line-data{width:99%}
div.unbreakable{page-break-inside:avoid}
.big{font-size:larger}
.small{font-size:smaller}
.underline{text-decoration:underline}
.overline{text-decoration:overline}
.line-through{text-decoration:line-through}
.aqua{color:#00bfbf}
.aqua-background{background:#00fafa}
.black{color:#000}
.black-background{background:#000}
.blue{color:#0000bf}
.blue-background{background:#0000fa}
.fuchsia{color:#bf00bf}
.fuchsia-background{background:#fa00fa}
.gray{color:#606060}
.gray-background{background:#7d7d7d}
.green{color:#006000}
.green-background{background:#007d00}
.lime{color:#00bf00}
.lime-background{background:#00fa00}
.maroon{color:#600000}
.maroon-background{background:#7d0000}
.navy{color:#000060}
.navy-background{background:#00007d}
.olive{color:#606000}
.olive-background{background:#7d7d00}
.purple{color:#600060}
.purple-background{background:#7d007d}
.red{color:#bf0000}
.red-background{background:#fa0000}
.silver{color:#909090}
.silver-background{background:#bcbcbc}
.teal{color:#006060}
.teal-background{background:#007d7d}
.white{color:#bfbfbf}
.white-background{background:#fafafa}
.yellow{color:#bfbf00}
.yellow-background{background:#fafa00}
span.icon>.fa{cursor:default}
a span.icon>.fa{cursor:inherit}
.admonitionblock td.icon [class^="fa icon-"]{font-size:2.5em;text-shadow:1px 1px 2px rgba(0,0,0,.5);cursor:default}
.admonitionblock td.icon .icon-note::before{content:"\f05a";color:#19407c}
.admonitionblock td.icon .icon-tip::before{content:"\f0eb";text-shadow:1px 1px 2px rgba(155,155,0,.8);color:#111}
.admonitionblock td.icon .icon-warning::before{content:"\f071";color:#bf6900}
.admonitionblock td.icon .icon-caution::before{content:"\f06d";color:#bf3400}
.admonitionblock td.icon .icon-important::before{content:"\f06a";color:#bf0000}
.conum[data-value]{display:inline-block;color:#fff!important;background:rgba(0,0,0,.8);-webkit-border-radius:100px;border-radius:100px;text-align:center;font-size:.75em;width:1.67em;height:1.67em;line-height:1.67em;font-family:"Open Sans","DejaVu Sans",sans-serif;font-style:normal;font-weight:bold}
.conum[data-value] *{color:#fff!important}
.conum[data-value]+b{display:none}
.conum[data-value]::after{content:attr(data-value)}
pre .conum[data-value]{position:relative;top:-.125em}
b.conum *{color:inherit!important}
.conum:not([data-value]):empty{display:none}
dt,th.tableblock,td.content,div.footnote{text-rendering:optimizeLegibility}
h1,h2,p,td.content,span.alt{letter-spacing:-.01em}
p strong,td.content strong,div.footnote strong{letter-spacing:-.005em}
p,blockquote,dt,td.content,span.alt{font-size:1.0625rem}
p{margin-bottom:1.25rem}
.sidebarblock p,.sidebarblock dt,.sidebarblock td.content,p.tableblock{font-size:1em}
.exampleblock>.content{background:#fffef7;border-color:#e0e0dc;-webkit-box-shadow:0 1px 4px #e0e0dc;box-shadow:0 1px 4px #e0e0dc}
.print-only{display:none!important}
@page{margin:1.25cm .75cm}
@media print{*{-webkit-box-shadow:none!important;box-shadow:none!important;text-shadow:none!important}
html{font-size:80%}
a{color:inherit!important;text-decoration:underline!important}
a.bare,a[href^="#"],a[href^="mailto:"]{text-decoration:none!important}
a[href^="http:"]:not(.bare)::after,a[href^="https:"]:not(.bare)::after{content:"(" attr(href) ")";display:inline-block;font-size:.875em;padding-left:.25em}
abbr[title]::after{content:" (" attr(title) ")"}
pre,blockquote,tr,img,object,svg{page-break-inside:avoid}
thead{display:table-header-group}
svg{max-width:100%}
p,blockquote,dt,td.content{font-size:1em;orphans:3;widows:3}
h2,h3,#toctitle,.sidebarblock>.content>.title{page-break-after:avoid}
#toc,.sidebarblock,.exampleblock>.content{background:none!important}
#toc{border-bottom:1px solid #dddddf!important;padding-bottom:0!important}
body.book #header{text-align:center}
body.book #header>h1:first-child{border:0!important;margin:2.5em 0 1em}
body.book #header .details{border:0!important;display:block;padding:0!important}
body.book #header .details span:first-child{margin-left:0!important}
body.book #header .details br{display:block}
body.book #header .details br+span::before{content:none!important}
body.book #toc{border:0!important;text-align:left!important;padding:0!important;margin:0!important}
body.book #toc,body.book #preamble,body.book h1.sect0,body.book .sect1>h2{page-break-before:always}
.listingblock code[data-lang]::before{display:block}
#footer{padding:0 .9375em}
.hide-on-print{display:none!important}
.print-only{display:block!important}
.hide-for-print{display:none!important}
.show-for-print{display:inherit!important}}
@media print,amzn-kf8{#header>h1:first-child{margin-top:1.25rem}
.sect1{padding:0!important}
.sect1+.sect1{border:0}
#footer{background:none}
#footer-text{color:rgba(0,0,0,.6);font-size:.9em}}
@media amzn-kf8{#header,#content,#footnotes,#footer{padding:0}}
</style>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
</head>
<body class="article toc2 toc-right">
<div id="header">
<h1>Deploying and Managing OpenShift Container Storage</h1>
<div id="toc" class="toc2">
<div id="toctitle">Table of Contents</div>
<ul class="sectlevel1">
<li><a href="#_lab_overview">1. Lab Overview</a>
<ul class="sectlevel2">
<li><a href="#_in_this_lab_you_will_learn_how_to">1.1. In this lab you will learn how to</a></li>
</ul>
</li>
<li><a href="#labexercises">2. Deploy your storage backend using the OCS operator</a>
<ul class="sectlevel2">
<li><a href="#_scale_ocp_cluster_and_add_3_new_nodes">2.1. Scale OCP cluster and add 3 new nodes</a></li>
<li><a href="#_installing_the_ocs_operator">2.2. Installing the OCS operator</a></li>
<li><a href="#_getting_to_know_the_storage_dashboards">2.3. Getting to know the Storage Dashboards</a></li>
<li><a href="#_using_the_rook_ceph_toolbox_to_check_on_the_ceph_backing_storage">2.4. Using the Rook-Ceph toolbox to check on the Ceph backing storage</a></li>
</ul>
</li>
<li><a href="#_create_a_new_ocp_application_deployment_using_ceph_rbd_volume">3. Create a new OCP application deployment using Ceph RBD volume</a>
<ul class="sectlevel2">
<li><a href="#_matching_pvs_to_rbds">3.1. Matching PVs to RBDs</a></li>
</ul>
</li>
<li><a href="#_create_a_new_ocp_application_deployment_using_cephfs_volume">4. Create a new OCP application deployment using CephFS volume</a></li>
<li><a href="#_using_ocs_for_prometheus_metrics">5. Using OCS for Prometheus Metrics</a>
<ul class="sectlevel2">
<li><a href="#_modifying_your_prometheus_environment">5.1. Modifying your Prometheus environment</a></li>
</ul>
</li>
<li><a href="#_using_the_multi_cloud_gateway">6. Using the Multi-Cloud-Gateway</a>
<ul class="sectlevel2">
<li><a href="#_checking_on_the_mcg_status">6.1. Checking on the MCG status</a></li>
<li><a href="#_creating_an_object_bucket_claim">6.2. Creating an Object Bucket Claim</a></li>
<li><a href="#_using_an_obc_inside_a_container">6.3. Using an OBC inside a container</a></li>
</ul>
</li>
<li><a href="#_adding_storage_to_the_ceph_cluster">7. Adding storage to the Ceph Cluster</a>
<ul class="sectlevel2">
<li><a href="#_add_storage_worker_nodes">7.1. Add storage worker nodes</a></li>
<li><a href="#_add_storage_capacity">7.2. Add storage capacity</a></li>
<li><a href="#_verify_new_storage">7.3. Verify new storage</a></li>
</ul>
</li>
<li><a href="#_monitoring_the_ocs_environment">8. Monitoring the OCS environment</a>
<ul class="sectlevel2">
<li><a href="#_alerting">8.1. Alerting</a></li>
<li><a href="#_metrics">8.2. Metrics</a></li>
</ul>
</li>
<li><a href="#_using_must_gather">9. Using must-gather</a></li>
<li><a href="#_introduction_to_ceph">Appendix A: Introduction to Ceph</a></li>
</ul>
</div>
</div>
<div id="content">
<div class="sect1">
<h2 id="_lab_overview">1. Lab Overview</h2>
<div class="sectionbody">
<div class="paragraph">
<p>This hands-on workshop is for both system administrators and application developers interested in learning how to deploy and manage OpenShift Container Storage (OCS). In this lab you will be using OpenShift Container Platform (OCP) 4.x and the OCS operator to deploy Ceph and the Multi-Cloud-Gateway (MCG) as a persistent storage solution for OCP workloads.
This instruction was developed using the RHPDS <code>OpenShift 4.2 Workshop</code>. Instructions to <code>Order</code> this Workshop for Red Hat employees can be found at <a href="https://mojo.redhat.com/docs/DOC-1209703">OpenShift 4.2 Workshop</a>. If you are not a Red Hat employee you can deploy OpenShift 4 using this link <a href="http:try.openshift.com">OpenShift 4 Deployment</a> and then follow the instructions for AWS Installer-Provisioned Infrastructure (IPI).</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
If deploying OpenShift 4 on VMware infrastructure or other User-Provisioned Infrastructure (UPI) skip the steps that include creating <strong>machines</strong> and <strong>machinesets</strong> given these resources are not currently available for UPI. To complete all of the instructions in this lab you will need to pre-provision six OCP worker nodes if OCP 4 is on UPI (i.e. not on AWS). To deploy OCS, OCP worker nodes need to have a minimum of 16 CPUs and 64 GB memory available.
</td>
</tr>
</table>
</div>
<div class="sect2">
<h3 id="_in_this_lab_you_will_learn_how_to">1.1. In this lab you will learn how to</h3>
<div class="ulist">
<ul>
<li>
<p>Configure and deploy containerized Ceph and NooBaa</p>
</li>
<li>
<p>Validate deployment of containerized Ceph and NooBaa</p>
</li>
<li>
<p>Deploy the Rook toolbox to run Ceph and RADOS commands</p>
</li>
<li>
<p>Creating a Read-Write-Once (RWO) PVC that is based on Ceph RBDs</p>
</li>
<li>
<p>Creating a Read-Write-Many (RWX) PVC that is based on CephFS</p>
</li>
<li>
<p>Use OCS for Prometheus and AlertManager storage</p>
</li>
<li>
<p>Use the MCG to create a bucket and use in an application</p>
</li>
<li>
<p>Add more storage to the Ceph cluster</p>
</li>
<li>
<p>Use must-gather to collect support information</p>
</li>
</ul>
</div>
<div class="imageblock">
<div class="content">
<img src="images/ocs/OCS-Pods-Diagram.png" alt="Showing OCS4 pods">
</div>
<div class="title">Figure 1. OpenShift Container Storage components</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
If you want more information about how Ceph works please review <a href="#_introduction_to_ceph">Introduction to Ceph</a> section before starting the exercises in this module.
</td>
</tr>
</table>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="labexercises">2. Deploy your storage backend using the OCS operator</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_scale_ocp_cluster_and_add_3_new_nodes">2.1. Scale OCP cluster and add 3 new nodes</h3>
<div class="paragraph">
<p>In this section, you will first validate the OCP environment has 3 master and 3 worker nodes before increasing the cluster size by additional 3 worker nodes for OCS resources. The <code>NAME</code> of your OCP nodes will be different than shown below.</p>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="pygments highlight"><code data-lang="shell"><span></span>oc get nodes -l node-role.kubernetes.io/worker</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Example output:</div>
<div class="content">
<pre class="pygments highlight"><code data-lang="shell"><span></span>NAME                                         STATUS   ROLES    AGE   VERSION
ip-10-0-138-9.us-east-2.compute.internal     Ready    worker   77m   v1.14.6+9fb2d5cf9
ip-10-0-150-39.us-east-2.compute.internal    Ready    worker   77m   v1.14.6+9fb2d5cf9
ip-10-0-170-49.us-east-2.compute.internal    Ready    worker   77m   v1.14.6+9fb2d5cf9</code></pre>
</div>
</div>
<div class="paragraph">
<p>Now you are going to add 3 more OCP compute nodes to cluster using <strong>machinesets</strong>.</p>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="pygments highlight"><code data-lang="shell"><span></span>oc get machinesets -n openshift-machine-api <span class="tok-p">|</span> grep -v infra</code></pre>
</div>
</div>
<div class="paragraph">
<p>This will show you the existing <strong>machinesets</strong> used to create the 3 worker nodes in the cluster already. There is a <strong>machineset</strong> for each AWS AZ (us-east-1a, us-east-1b, us-east-1c). Your <strong>machinesets</strong> <code>NAME</code> will be different than below.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight"><code data-lang="shell"><span></span>NAME                                       DESIRED   CURRENT   READY   AVAILABLE   AGE
cluster-ocs-0ec4-dgwqc-worker-us-east-2a   <span class="tok-m">1</span>         <span class="tok-m">1</span>         <span class="tok-m">1</span>       <span class="tok-m">1</span>           86m
cluster-ocs-0ec4-dgwqc-worker-us-east-2b   <span class="tok-m">1</span>         <span class="tok-m">1</span>         <span class="tok-m">1</span>       <span class="tok-m">1</span>           86m
cluster-ocs-0ec4-dgwqc-worker-us-east-2c   <span class="tok-m">1</span>         <span class="tok-m">1</span>         <span class="tok-m">1</span>       <span class="tok-m">1</span>           86m</code></pre>
</div>
</div>
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<i class="fa icon-warning" title="Warning"></i>
</td>
<td class="content">
<strong>Make sure you do the next step for finding and using your CLUSTERID</strong>
</td>
</tr>
</table>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="pygments highlight"><code data-lang="shell"><span></span><span class="tok-nv">CLUSTERID</span><span class="tok-o">=</span><span class="tok-k">$(</span>oc get machineset -n openshift-machine-api -o <span class="tok-nv">jsonpath</span><span class="tok-o">=</span><span class="tok-s1">&#39;{.items[0].metadata.labels.machine\.openshift\.io/cluster-api-cluster}&#39;</span><span class="tok-k">)</span>
<span class="tok-nb">echo</span> <span class="tok-nv">$CLUSTERID</span>
curl -s https://lfbf6bao0k.execute-api.eu-central-1.amazonaws.com/machineset-lambda?clusterID<span class="tok-o">=</span><span class="tok-nv">$CLUSTERID</span> <span class="tok-p">|</span> oc apply -f -</code></pre>
</div>
</div>
<div class="paragraph">
<p>Check that you have new <strong>machines</strong> created.</p>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="pygments highlight"><code data-lang="shell"><span></span>oc get machines -n openshift-machine-api <span class="tok-p">|</span> egrep <span class="tok-s1">&#39;NAME|workerocs&#39;</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>They may be in <code>pending</code> for sometime so repeat command above until they are in a <code>running</code> STATE. The <code>NAME</code> of your machines will be different than shown below.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight"><code data-lang="shell"><span></span>NAME                                                STATE     TYPE         REGION      ZONE         AGE
cluster-ocs-0ec4-dgwqc-workerocs-us-east-2a-cqvwj   running   m5.4xlarge   us-east-2   us-east-2a   70s
cluster-ocs-0ec4-dgwqc-workerocs-us-east-2b-g5p5v   running   m5.4xlarge   us-east-2   us-east-2b   70s
cluster-ocs-0ec4-dgwqc-workerocs-us-east-2c-rx4v8   running   m5.4xlarge   us-east-2   us-east-2c   70s</code></pre>
</div>
</div>
<div class="paragraph">
<p>You can see that the workerocs <strong>machines</strong> are using are also using the AWS EC2 instance type <code>m5.4xlarge</code>. The <code>m5.4xlarge</code> instance type follows our recommended instance sizing for OCS, 16 cpu and 64 GB mem.</p>
</div>
<div class="paragraph">
<p>Now you want to see if our new <strong>machines</strong> are added to the OCP cluster.</p>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="pygments highlight"><code data-lang="shell"><span></span>watch <span class="tok-s2">&quot;oc get machinesets -n openshift-machine-api | egrep &#39;NAME|workerocs&#39;&quot;</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>This step could take more than 5 minutes. The result of this command needs to look like below before you proceed. All new workerocs <strong>machinesets</strong> should have an integer, in this case <code>1</code>, filled out for all rows and under columns <code>READY</code> and <code>AVAILABLE</code>. The <code>NAME</code> of your <strong>machinesets</strong> will be different than shown below.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight"><code data-lang="shell"><span></span>NAME                                          DESIRED   CURRENT   READY   AVAILABLE   AGE
cluster-ocs-0ec4-dgwqc-workerocs-us-east-2a   <span class="tok-m">1</span>         <span class="tok-m">1</span>         <span class="tok-m">1</span>       <span class="tok-m">1</span>           8m26s
cluster-ocs-0ec4-dgwqc-workerocs-us-east-2b   <span class="tok-m">1</span>         <span class="tok-m">1</span>         <span class="tok-m">1</span>       <span class="tok-m">1</span>           8m26s
cluster-ocs-0ec4-dgwqc-workerocs-us-east-2c   <span class="tok-m">1</span>         <span class="tok-m">1</span>         <span class="tok-m">1</span>       <span class="tok-m">1</span>           8m25s</code></pre>
</div>
</div>
<div class="paragraph">
<p>You can exit by pressing <span class="keyseq"><kbd>Ctrl</kbd>+<kbd>C</kbd></span></p>
</div>
<div class="paragraph">
<p>Now check to see that you have 3 new OCP worker nodes. The <code>NAME</code> of your OCP nodes will be different than shown below.</p>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="pygments highlight"><code data-lang="shell"><span></span>oc get nodes -l node-role.kubernetes.io/worker</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Example output:</div>
<div class="content">
<pre class="pygments highlight"><code data-lang="shell"><span></span>NAME                                         STATUS   ROLES    AGE     VERSION
ip-10-0-131-209.us-east-2.compute.internal   Ready    worker   2m21s   v1.14.6+9fb2d5cf9
ip-10-0-138-9.us-east-2.compute.internal     Ready    worker   128m    v1.14.6+9fb2d5cf9
ip-10-0-150-39.us-east-2.compute.internal    Ready    worker   128m    v1.14.6+9fb2d5cf9
ip-10-0-155-12.us-east-2.compute.internal    Ready    worker   2m22s   v1.14.6+9fb2d5cf9
ip-10-0-162-215.us-east-2.compute.internal   Ready    worker   2m14s   v1.14.6+9fb2d5cf9
ip-10-0-170-49.us-east-2.compute.internal    Ready    worker   128m    v1.14.6+9fb2d5cf9</code></pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_installing_the_ocs_operator">2.2. Installing the OCS operator</h3>
<div class="paragraph">
<p>In this section you will be using three of the worker OCP 4 nodes to deploy OCS 4 using the OCS Operator in OperatorHub. The following will be installed:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Groups and sources for the OCS operators</p>
</li>
<li>
<p>An OCS subscription</p>
</li>
<li>
<p>All OCS resources (Operators, Ceph pods, Noobaa pods, StorageClasses)</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Start with creating the <code>openshift-storage</code> namespace.</p>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="pygments highlight"><code data-lang="shell"><span></span>oc create namespace openshift-storage</code></pre>
</div>
</div>
<div class="paragraph">
<p>You must add the monitoring label to this namespace. This is required to get prometheus metrics and alerts for the OCP storage dashboards. To label the <code>openshift-storage</code> namespace use the following command:</p>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="pygments highlight"><code data-lang="shell"><span></span>oc label namespace openshift-storage <span class="tok-s2">&quot;openshift.io/cluster-monitoring=true&quot;</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>Now switch over to your <strong>Openshift Web Console</strong>. You can get your URL by issuing command below to get the OCP 4 <code>console</code> route. Put this URL in a browser tab. You will use the same Admin username and password you used to login and use the <code>oc client</code> to login to the OCP 4 <code>console</code>.</p>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="pygments highlight"><code data-lang="shell"><span></span>oc get -n openshift-console route console</code></pre>
</div>
</div>
<div class="paragraph">
<p>Once you are logged in, navigate to the <strong>OperatorHub</strong> menu.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/ocs/OCS-OCP-OperatorHub.png" alt="OCP OperatorHub">
</div>
<div class="title">Figure 2. OCP OperatorHub</div>
</div>
<div class="paragraph">
<p>Now type <code>container storage</code> in the <strong>Filter by <em>keyword&#8230;&#8203;</em></strong> box.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/ocs/OCS-OCP-OperatorHub-Filter.png" alt="OCP OperatorHub Filter">
</div>
<div class="title">Figure 3. OCP OperatorHub filter on OpenShift Container Storage Operator</div>
</div>
<div class="paragraph">
<p>Select <code>OpenShift Container Storage Operator</code> and then select <strong>Install</strong>.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/ocs/OCS-OCP-OperatorHub-Install.png" alt="OCP OperatorHub Install">
</div>
<div class="title">Figure 4. OCP OperatorHub Install OpenShift Container Storage</div>
</div>
<div class="paragraph">
<p>On the next screen make sure the settings are as shown in this figure. Make sure to change to <code>A specific namespace on the cluster</code> and chose namespace <code>openshift-storage</code>. Click <code>Subscribe</code>.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/ocs/OCS-OCP-OperatorHub-Subscribe.png" alt="OCP OperatorHub Subscribe">
</div>
<div class="title">Figure 5. OCP Subscribe to OpenShift Container Storage</div>
</div>
<div class="paragraph">
<p>Now you can go back to your terminal window to check the progress of the installation.</p>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="pygments highlight"><code data-lang="shell"><span></span>watch oc -n openshift-storage get csv</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Example output:</div>
<div class="content">
<pre class="pygments highlight"><code data-lang="shell"><span></span>NAME                  DISPLAY                       VERSION   REPLACES   PHASE
ocs-operator.v4.2.0   OpenShift Container Storage   <span class="tok-m">4</span>.2.0                Succeeded</code></pre>
</div>
</div>
<div class="paragraph">
<p>You can exit by pressing <span class="keyseq"><kbd>Ctrl</kbd>+<kbd>C</kbd></span></p>
</div>
<div class="paragraph">
<p>The resource <code>csv</code> is a shortened word for <code>clusterserviceversions.operators.coreos.com</code>.</p>
</div>
<div class="admonitionblock caution">
<table>
<tr>
<td class="icon">
<i class="fa icon-caution" title="Caution"></i>
</td>
<td class="content">
<div class="title">Please wait until the operator <code>PHASE</code> changes to <code>Succeeded</code></div>
This will mark that the installation of your operator was successful. Reaching this state can take several minutes.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>You will now also see some new operator pods in the new <code>openshift-storage</code> namespace:</p>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="pygments highlight"><code data-lang="shell"><span></span>oc -n openshift-storage get pods</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Example output:</div>
<div class="content">
<pre class="pygments highlight"><code data-lang="shell"><span></span>NAME                                 READY   STATUS    RESTARTS   AGE
noobaa-operator-6d59cd7855-lhwg8     <span class="tok-m">1</span>/1     Running   <span class="tok-m">0</span>          79s
ocs-operator-dc48d685-8qtqn          <span class="tok-m">1</span>/1     Running   <span class="tok-m">0</span>          79s
rook-ceph-operator-d857c476f-4npzl   <span class="tok-m">1</span>/1     Running   <span class="tok-m">0</span>          79s</code></pre>
</div>
</div>
<div class="paragraph">
<p>Now switch back to your <strong>Openshift Web Console</strong> for the remainder of the installation for OCS 4.</p>
</div>
<div class="paragraph">
<p>Navigate to the <code>Operators</code> menu on the left and select <code>Installed Operators</code>. Make sure the selected project is set to <code>openshift-storage</code>.
What you see, should be similar to the following example picture:</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/ocs/OCP-installed-operators.png" alt="Openshift showing the installed operators in namespace openshift-storage">
</div>
<div class="title">Figure 6. Installed operators:  1) Make sure you are in the right project; 2) Check Operator status; 3) Click on Openshift Container Storage Operator</div>
</div>
<div class="paragraph">
<p>Click on <code>Openshift Container Storage Operator</code> to get to the OCS configuration screen.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/ocs/OCS-config-screen-all.png" alt="OCS configuration screen">
</div>
<div class="title">Figure 7. OCS configuration screen</div>
</div>
<div class="paragraph">
<p>On the top of the OCS configuration screen, scroll over to the right and click on <code>Storage cluster</code> and then click on <code>Create OCS Cluster Service</code>. If you do not see <code>Create OCS Cluster Service</code> refresh your browser window.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/ocs/OCS-config-screen-storage-cluster.png" alt="OCS Create Storage Cluster">
</div>
<div class="title">Figure 8. OCS Create Storage Cluster</div>
</div>
<div class="paragraph">
<p>A dialog box will come up next.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/ocs/OCS-config-screen-new.png" alt="OCS create a new storage cluster">
</div>
<div class="title">Figure 9. OCS create a new storage cluster</div>
</div>
<div class="admonitionblock caution">
<table>
<tr>
<td class="icon">
<i class="fa icon-caution" title="Caution"></i>
</td>
<td class="content">
<strong>Make sure to select three workers in different availability zones using instructions below</strong>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>To select the appropriate worker nodes of your OCP 4 cluster you can find them by searching for the node label <code>role=storage-node</code>.</p>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="pygments highlight"><code data-lang="shell"><span></span>oc get nodes --show-labels <span class="tok-p">|</span> grep storage-node <span class="tok-p">|</span>cut -d<span class="tok-s1">&#39; &#39;</span> -f1</code></pre>
</div>
</div>
<div class="paragraph">
<p>Select the three nodes that resulted from the command above. Then click on the button <code>Create</code> below the dialog box where you selected the 3 workers with a <code>checkmark</code>.</p>
</div>
<div class="paragraph">
<p>In the background this will start initiating a lot of new pods in the <code>openshift-storage</code> namespace, as can be seen on the CLI:</p>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="pygments highlight"><code data-lang="shell"><span></span>oc -n openshift-storage get pods</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Example of a in process installation of the OCS storage cluster:</div>
<div class="content">
<pre class="pygments highlight"><code data-lang="shell"><span></span>NAME                                          READY   STATUS              RESTARTS   AGE
csi-cephfsplugin-6t5cc                        <span class="tok-m">0</span>/3     ContainerCreating   <span class="tok-m">0</span>          21s
csi-cephfsplugin-7slmp                        <span class="tok-m">0</span>/3     ContainerCreating   <span class="tok-m">0</span>          21s
csi-cephfsplugin-865k6                        <span class="tok-m">0</span>/3     ContainerCreating   <span class="tok-m">0</span>          21s
csi-cephfsplugin-8zn2w                        <span class="tok-m">0</span>/3     ContainerCreating   <span class="tok-m">0</span>          21s
csi-cephfsplugin-9mmkp                        <span class="tok-m">0</span>/3     ContainerCreating   <span class="tok-m">0</span>          21s
csi-cephfsplugin-provisioner-57f9567c-g44d6   <span class="tok-m">0</span>/4     ContainerCreating   <span class="tok-m">0</span>          21s
csi-cephfsplugin-provisioner-57f9567c-tlnjz   <span class="tok-m">0</span>/4     ContainerCreating   <span class="tok-m">0</span>          21s
csi-cephfsplugin-q86tr                        <span class="tok-m">0</span>/3     ContainerCreating   <span class="tok-m">0</span>          21s
csi-rbdplugin-24t87                           <span class="tok-m">0</span>/3     ContainerCreating   <span class="tok-m">0</span>          21s
csi-rbdplugin-4zp5v                           <span class="tok-m">0</span>/3     ContainerCreating   <span class="tok-m">0</span>          21s
csi-rbdplugin-5s5dc                           <span class="tok-m">0</span>/3     ContainerCreating   <span class="tok-m">0</span>          21s
csi-rbdplugin-fjl6s                           <span class="tok-m">0</span>/3     ContainerCreating   <span class="tok-m">0</span>          21s
csi-rbdplugin-mrkr5                           <span class="tok-m">0</span>/3     ContainerCreating   <span class="tok-m">0</span>          21s
csi-rbdplugin-pr9hn                           <span class="tok-m">0</span>/3     ContainerCreating   <span class="tok-m">0</span>          21s
csi-rbdplugin-provisioner-69bb78d655-4hrzx    <span class="tok-m">0</span>/4     ContainerCreating   <span class="tok-m">0</span>          21s
csi-rbdplugin-provisioner-69bb78d655-clzk5    <span class="tok-m">0</span>/4     ContainerCreating   <span class="tok-m">0</span>          21s
noobaa-operator-6d59cd7855-lhwg8              <span class="tok-m">1</span>/1     Running             <span class="tok-m">0</span>          2m59s
ocs-operator-dc48d685-8qtqn                   <span class="tok-m">0</span>/1     Running             <span class="tok-m">0</span>          2m59s
rook-ceph-detect-version-znh2f                <span class="tok-m">0</span>/1     Init:0/1            <span class="tok-m">0</span>          15s
rook-ceph-operator-d857c476f-4npzl            <span class="tok-m">1</span>/1     Running             <span class="tok-m">0</span>          2m59s</code></pre>
</div>
</div>
<div class="paragraph">
<p>You can also watch the deployment using the <strong>Openshift Web Console</strong> by going back to the <code>Openshift Container Storage Operator</code> screen and selecting <code>All instances</code>.</p>
</div>
<div class="paragraph">
<p>Please wait until all <strong>Pods</strong> are marked as <code>Running</code> in the CLI or until you see all instances shown below as <code>Ready</code> Status in the Web Console. Some instances may stay in <code>Unknown</code> Status which is not a concern if your <code>Ready</code> status matches the following diagram:</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/ocs/OCS-finished-cluster-install.png" alt="OCS instance overview after cluster install is finished">
</div>
<div class="title">Figure 10. OCS instance overview after cluster install is finished</div>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="pygments highlight"><code data-lang="shell"><span></span>oc -n openshift-storage get pods</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Output when the cluster installation is finished</div>
<div class="content">
<pre class="pygments highlight"><code data-lang="shell"><span></span>NAME                                                              READY   STATUS      RESTARTS   AGE
csi-cephfsplugin-6t5cc                                            <span class="tok-m">3</span>/3     Running     <span class="tok-m">0</span>          9m30s
csi-cephfsplugin-7slmp                                            <span class="tok-m">3</span>/3     Running     <span class="tok-m">0</span>          9m30s
csi-cephfsplugin-865k6                                            <span class="tok-m">3</span>/3     Running     <span class="tok-m">0</span>          9m30s
csi-cephfsplugin-8zn2w                                            <span class="tok-m">3</span>/3     Running     <span class="tok-m">0</span>          9m30s
csi-cephfsplugin-9mmkp                                            <span class="tok-m">3</span>/3     Running     <span class="tok-m">0</span>          9m30s
csi-cephfsplugin-provisioner-57f9567c-g44d6                       <span class="tok-m">4</span>/4     Running     <span class="tok-m">0</span>          9m30s
csi-cephfsplugin-provisioner-57f9567c-tlnjz                       <span class="tok-m">4</span>/4     Running     <span class="tok-m">0</span>          9m30s
csi-cephfsplugin-q86tr                                            <span class="tok-m">3</span>/3     Running     <span class="tok-m">0</span>          9m30s
csi-rbdplugin-24t87                                               <span class="tok-m">3</span>/3     Running     <span class="tok-m">0</span>          9m30s
csi-rbdplugin-4zp5v                                               <span class="tok-m">3</span>/3     Running     <span class="tok-m">0</span>          9m30s
csi-rbdplugin-5s5dc                                               <span class="tok-m">3</span>/3     Running     <span class="tok-m">0</span>          9m30s
csi-rbdplugin-fjl6s                                               <span class="tok-m">3</span>/3     Running     <span class="tok-m">0</span>          9m30s
csi-rbdplugin-mrkr5                                               <span class="tok-m">3</span>/3     Running     <span class="tok-m">0</span>          9m30s
csi-rbdplugin-pr9hn                                               <span class="tok-m">3</span>/3     Running     <span class="tok-m">0</span>          9m30s
csi-rbdplugin-provisioner-69bb78d655-4hrzx                        <span class="tok-m">4</span>/4     Running     <span class="tok-m">0</span>          9m30s
csi-rbdplugin-provisioner-69bb78d655-clzk5                        <span class="tok-m">4</span>/4     Running     <span class="tok-m">0</span>          9m30s
noobaa-core-0                                                     <span class="tok-m">2</span>/2     Running     <span class="tok-m">0</span>          5m38s
noobaa-operator-6d59cd7855-lhwg8                                  <span class="tok-m">1</span>/1     Running     <span class="tok-m">0</span>          12m
ocs-operator-dc48d685-8qtqn                                       <span class="tok-m">1</span>/1     Running     <span class="tok-m">0</span>          12m
rook-ceph-drain-canary-731c9dd8472082ee17090f034387aa3b-78k55k9   <span class="tok-m">1</span>/1     Running     <span class="tok-m">0</span>          5m48s
rook-ceph-drain-canary-93e6590ed0bb3c88b985beb159ef084a-7c8kpsg   <span class="tok-m">1</span>/1     Running     <span class="tok-m">0</span>          5m55s
rook-ceph-drain-canary-d0eaaceda4b757fe363def0873a5f86f-98s5k27   <span class="tok-m">1</span>/1     Running     <span class="tok-m">0</span>          5m45s
rook-ceph-mds-ocs-storagecluster-cephfilesystem-a-7c865846g6k27   <span class="tok-m">1</span>/1     Running     <span class="tok-m">0</span>          5m33s
rook-ceph-mds-ocs-storagecluster-cephfilesystem-b-69f846986g4n7   <span class="tok-m">1</span>/1     Running     <span class="tok-m">0</span>          5m32s
rook-ceph-mgr-a-5486fc7cf5-l9h6z                                  <span class="tok-m">1</span>/1     Running     <span class="tok-m">0</span>          6m44s
rook-ceph-mon-a-58c7cd4f9b-g4z2m                                  <span class="tok-m">1</span>/1     Running     <span class="tok-m">0</span>          8m17s
rook-ceph-mon-b-684f66b8df-992wc                                  <span class="tok-m">1</span>/1     Running     <span class="tok-m">0</span>          7m43s
rook-ceph-mon-c-6f7657b8b6-2sxl5                                  <span class="tok-m">1</span>/1     Running     <span class="tok-m">0</span>          7m13s
rook-ceph-operator-d857c476f-4npzl                                <span class="tok-m">1</span>/1     Running     <span class="tok-m">0</span>          12m
rook-ceph-osd-0-8675cf4f4-7gpbv                                   <span class="tok-m">1</span>/1     Running     <span class="tok-m">0</span>          5m55s
rook-ceph-osd-1-58b9d954cf-9s6bw                                  <span class="tok-m">1</span>/1     Running     <span class="tok-m">0</span>          5m48s
rook-ceph-osd-2-6994dd5f44-hsqrv                                  <span class="tok-m">1</span>/1     Running     <span class="tok-m">0</span>          5m45s
rook-ceph-osd-prepare-ocs-deviceset-0-0-d2ppm-vvlt8               <span class="tok-m">0</span>/1     Completed   <span class="tok-m">0</span>          6m22s
rook-ceph-osd-prepare-ocs-deviceset-1-0-9tmc6-svb84               <span class="tok-m">0</span>/1     Completed   <span class="tok-m">0</span>          6m22s
rook-ceph-osd-prepare-ocs-deviceset-2-0-qtbfv-j4nr4               <span class="tok-m">0</span>/1     Completed   <span class="tok-m">0</span>          6m21s</code></pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_getting_to_know_the_storage_dashboards">2.3. Getting to know the Storage Dashboards</h3>
<div class="paragraph">
<p>You can now also check the status of your storage cluster with the OCS specific <strong>Dashboards</strong> that are included in your <strong>Openshift Web Console</strong>. You can reach this by clicking on <code>Home</code> on your left navigation bar, then selecting <code>Dashboards</code> and finally clicking on <code>Persistent Storage</code> on the top navigation bar of the content page.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
If you just finished your OCS 4 deployment it could take 5-10 minutes for your <strong>Dashboards</strong> to fully populate.
</td>
</tr>
</table>
</div>
<div class="imageblock">
<div class="content">
<img src="images/ocs/OCS-dashboard-healthy.png" alt="OCS Dashboard after successful backing storage installation">
</div>
<div class="title">Figure 11. OCS Dashboard after successful backing storage installation</div>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 0%;">
<col style="width: 9.0909%;">
<col style="width: 90.9091%;">
</colgroup>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">&lt;1&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Health</p></td>
<td class="tableblock halign-left valign-top"><div class="content"><div class="paragraph">
<p>Quick overview of the general health of the storage cluster</p>
</div></div></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">&lt;2&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Details</p></td>
<td class="tableblock halign-left valign-top"><div class="content"><div class="paragraph">
<p>Overview of the deployed storage cluster version and backend provider</p>
</div></div></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">&lt;3&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Inventory</p></td>
<td class="tableblock halign-left valign-top"><div class="content"><div class="paragraph">
<p>List of all the resources that are used and offered by the storage system</p>
</div></div></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">&lt;4&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Events</p></td>
<td class="tableblock halign-left valign-top"><div class="content"><div class="paragraph">
<p>Live overview of all the changes that are being done affecting the storage cluster</p>
</div></div></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">&lt;5&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Utilization</p></td>
<td class="tableblock halign-left valign-top"><div class="content"><div class="paragraph">
<p>Overview of the storage cluster usage and performance</p>
</div></div></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p>OCS ships with a <strong>Dashboard</strong> for the Object Store service as well. From within the <strong>Dashboard</strong> menu click on the <code>Object Service</code> on the top navigation bar of the content page.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/ocs/OCS-noobaa-dashboard-healthy.png" alt="OCS Multi-Cloud-Gateway Dashboard after successful installation">
</div>
<div class="title">Figure 12. OCS Multi-Cloud-Gateway Dashboard after successful installation</div>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 0%;">
<col style="width: 9.0909%;">
<col style="width: 90.9091%;">
</colgroup>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">&lt;1&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Health</p></td>
<td class="tableblock halign-left valign-top"><div class="content"><div class="paragraph">
<p>Quick overview of the general health of the Multi-Cloud-Gateway</p>
</div></div></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">&lt;2&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Details</p></td>
<td class="tableblock halign-left valign-top"><div class="content"><div class="paragraph">
<p>Overview of the deployed MCG version and backend provider including a link to the MCG Dashboard</p>
</div></div></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">&lt;3&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Buckets</p></td>
<td class="tableblock halign-left valign-top"><div class="content"><div class="paragraph">
<p>List of all the ObjectBucket with are offered and ObjectBucketClaims which are connected to them</p>
</div></div></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">&lt;4&gt;</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Resource Providers</p></td>
<td class="tableblock halign-left valign-top"><div class="content"><div class="paragraph">
<p>Shows the list of configured Resource Providers that are available as backing storage in the MCG</p>
</div></div></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p>Once this is all healthy, you will be able to use the three new <strong>StorageClasses</strong> created during the OCS 4 Install:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>ocs-storagecluster-ceph-rbd</p>
</li>
<li>
<p>ocs-storagecluster-cephfs</p>
</li>
<li>
<p>openshift-storage.noobaa.io</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>You can see these three <strong>StorageClasses</strong> from the Openshift Web Console by expanding the <code>Storage</code> menu in the left navigation bar and selecting <code>Storage Classes</code>. You can also run the command below:</p>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="pygments highlight"><code data-lang="shell"><span></span>oc -n openshift-storage get sc</code></pre>
</div>
</div>
<div class="paragraph">
<p>Please make sure the three storage classes are available in your cluster before proceeding.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
The NooBaa pod used the <code>ocs-storagecluster-ceph-rbd</code> storage class for creating a PVC for mounting to it&#8217;s <code>db</code> container.
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="_using_the_rook_ceph_toolbox_to_check_on_the_ceph_backing_storage">2.4. Using the Rook-Ceph toolbox to check on the Ceph backing storage</h3>
<div class="paragraph">
<p>Since the Rook-Ceph <strong>toolbox</strong> is not shipped with OCS, we need to deploy it manually. For this, we can leverage the upstream <code>toolbox.yaml</code> file, but we need to modify the namespace as shown below.</p>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="pygments highlight"><code data-lang="shell"><span></span>oc apply <span class="tok-o">{{</span> HOME_PATH <span class="tok-o">}}</span>/support/ocslab_toolbox.yaml</code></pre>
</div>
</div>
<div class="paragraph">
<p>After the <code>rook-ceph-tools</code> <strong>Pod</strong> is <code>Running</code> you can access the toolbox like this:</p>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="pygments highlight"><code data-lang="shell"><span></span><span class="tok-nv">TOOLS_POD</span><span class="tok-o">=</span><span class="tok-k">$(</span>oc get pods -n openshift-storage -l <span class="tok-nv">app</span><span class="tok-o">=</span>rook-ceph-tools -o name<span class="tok-k">)</span>
oc rsh -n openshift-storage <span class="tok-nv">$TOOLS_POD</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>Once inside the toolbox, try out the following Ceph commands:</p>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="pygments highlight"><code data-lang="shell"><span></span>ceph status</code></pre>
</div>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="pygments highlight"><code data-lang="shell"><span></span>ceph osd status</code></pre>
</div>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="pygments highlight"><code data-lang="shell"><span></span>ceph osd tree</code></pre>
</div>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="pygments highlight"><code data-lang="shell"><span></span>ceph df</code></pre>
</div>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="pygments highlight"><code data-lang="shell"><span></span>rados df</code></pre>
</div>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="pygments highlight"><code data-lang="shell"><span></span>ceph versions</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Example output:</div>
<div class="content">
<pre class="pygments highlight"><code data-lang="shell"><span></span>sh-4.2# ceph status
  cluster:
    id:     786dbab2-ae4f-4352-8d83-5e27c6a4f341
    health: HEALTH_OK

  services:
    mon: <span class="tok-m">3</span> daemons, quorum a,b,c <span class="tok-o">(</span>age 105m<span class="tok-o">)</span>
    mgr: a<span class="tok-o">(</span>active, since 104m<span class="tok-o">)</span>
    mds: ocs-storagecluster-cephfilesystem:1 <span class="tok-o">{</span><span class="tok-nv">0</span><span class="tok-o">=</span>ocs-storagecluster-cephfilesystem-a<span class="tok-o">=</span>up:active<span class="tok-o">}</span> <span class="tok-m">1</span> up:standby-replay
    osd: <span class="tok-m">3</span> osds: <span class="tok-m">3</span> up <span class="tok-o">(</span>since 104m<span class="tok-o">)</span>, <span class="tok-m">3</span> in <span class="tok-o">(</span>since 104m<span class="tok-o">)</span>

  data:
    pools:   <span class="tok-m">3</span> pools, <span class="tok-m">24</span> pgs
    objects: <span class="tok-m">100</span> objects, <span class="tok-m">114</span> MiB
    usage:   <span class="tok-m">3</span>.2 GiB used, <span class="tok-m">3</span>.0 TiB / <span class="tok-m">3</span>.0 TiB avail
    pgs:     <span class="tok-m">24</span> active+clean

  io:
    client:   <span class="tok-m">1</span>.2 KiB/s rd, <span class="tok-m">39</span> KiB/s wr, <span class="tok-m">2</span> op/s rd, <span class="tok-m">3</span> op/s wr</code></pre>
</div>
</div>
<div class="paragraph">
<p>You can exit the toolbox by either pressing <span class="keyseq"><kbd>Ctrl</kbd>+<kbd>D</kbd></span> or by executing</p>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="pygments highlight"><code data-lang="shell"><span></span><span class="tok-nb">exit</span></code></pre>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_create_a_new_ocp_application_deployment_using_ceph_rbd_volume">3. Create a new OCP application deployment using Ceph RBD volume</h2>
<div class="sectionbody">
<div class="paragraph">
<p>In this section the <code>ocs-storagecluster-ceph-rbd</code> <strong>storage class</strong> will be used by an OCP application + database <strong>deployment</strong> to create RWO (ReadWriteOnce) persistent storage. The persistent storage will be a Ceph RBD (RADOS Block Device) volume (object) in the Ceph pool <code>ocs-storagecluster-cephblockpool</code>.</p>
</div>
<div class="paragraph">
<p>To do so we have created a template file, based on the OpenShift rails-pgsql-persistent template, that includes an extra parameter STORAGE_CLASS that enables the end user to specify the storage class the PVC should use.
Feel free to download <code><a href="https://raw.githubusercontent.com/red-hat-storage/ocs-training/master/ocp4ocs4/configurable-rails-app.yaml" class="bare">https://raw.githubusercontent.com/red-hat-storage/ocs-training/master/ocp4ocs4/configurable-rails-app.yaml</a></code> to check on the format of this template. Search for <code>STORAGE_CLASS</code> in the downloaded content.</p>
</div>
<div class="paragraph">
<p>Make sure that you completed all previous sections so that you are ready to start the Rails + PostgreSQL deployment.</p>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="pygments highlight"><code data-lang="shell"><span></span>oc new-project my-database-app
oc new-app <span class="tok-o">{{</span> HOME_PATH <span class="tok-o">}}</span>/support/ocslab_rails-app.yaml -p <span class="tok-nv">STORAGE_CLASS</span><span class="tok-o">=</span>ocs-storagecluster-ceph-rbd -p <span class="tok-nv">VOLUME_CAPACITY</span><span class="tok-o">=</span>5Gi</code></pre>
</div>
</div>
<div class="paragraph">
<p>After the deployment is started you can monitor with these commands.</p>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="pygments highlight"><code data-lang="shell"><span></span>oc status</code></pre>
</div>
</div>
<div class="paragraph">
<p>Check the PVC that were created.</p>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="pygments highlight"><code data-lang="shell"><span></span>oc get pvc -n my-database-app</code></pre>
</div>
</div>
<div class="paragraph">
<p>This step could take 5 or more minutes. Wait until there are 2 <strong>Pods</strong> in <code>Running</code> STATUS and 4 <strong>Pods</strong> in <code>Completed</code> STATUS as shown below.</p>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="pygments highlight"><code data-lang="shell"><span></span>watch oc get pods -n my-database-app</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Example output:</div>
<div class="content">
<pre class="pygments highlight"><code data-lang="shell"><span></span>NAME                                READY   STATUS      RESTARTS   AGE
postgresql-1-deploy                 <span class="tok-m">0</span>/1     Completed   <span class="tok-m">0</span>          5m48s
postgresql-1-lf7qt                  <span class="tok-m">1</span>/1     Running     <span class="tok-m">0</span>          5m40s
rails-pgsql-persistent-1-build      <span class="tok-m">0</span>/1     Completed   <span class="tok-m">0</span>          5m49s
rails-pgsql-persistent-1-deploy     <span class="tok-m">0</span>/1     Completed   <span class="tok-m">0</span>          3m36s
rails-pgsql-persistent-1-hook-pre   <span class="tok-m">0</span>/1     Completed   <span class="tok-m">0</span>          3m28s
rails-pgsql-persistent-1-pjh6q      <span class="tok-m">1</span>/1     Running     <span class="tok-m">0</span>          3m14s</code></pre>
</div>
</div>
<div class="paragraph">
<p>You can exit by pressing <span class="keyseq"><kbd>Ctrl</kbd>+<kbd>C</kbd></span></p>
</div>
<div class="paragraph">
<p>Once the deployment is complete you can now test the application and the persistent storage on Ceph. Your <code>HOST/PORT</code> will be different.</p>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="pygments highlight"><code data-lang="shell"><span></span>oc get route -n my-database-app</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Example output:</div>
<div class="content">
<pre class="pygments highlight"><code data-lang="shell"><span></span>NAME                     HOST/PORT                                                                         PATH   SERVICES                 PORT    TERMINATION   WILDCARD
rails-pgsql-persistent   rails-pgsql-persistent-my-database-app.apps.cluster-a26e.sandbox449.opentlc.com          rails-pgsql-persistent</code></pre>
</div>
</div>
<div class="paragraph">
<p>Copy your <code>rails-pgsql-persistent</code> route (different than above) to a browser window to create articles. You will need to append <code>/articles</code> to the end.</p>
</div>
<div class="paragraph">
<p><strong>Example</strong>  <a href="http://&lt;your_route&gt;/articles" class="bare">http://&lt;your_route&gt;/articles</a></p>
</div>
<div class="paragraph">
<p>Enter the <code>username</code> and <code>password</code> below to create articles and comments. The articles and comments are saved in a PostgreSQL database which stores its table spaces on the Ceph RBD volume provisioned using the <code>ocs-storagecluster-ceph-rbd</code> <strong>storageclass</strong> during the application deployment.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight"><code data-lang="ini"><span></span><span class="tok-na">username: openshift</span>
<span class="tok-na">password: secret</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>Lets now take another look at the Ceph <code>ocs-storagecluster-cephblockpool</code> created by the <code>ocs-storagecluster-ceph-rbd</code> <strong>Storage Class</strong>. Log into the <strong>toolbox</strong> pod again.</p>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="pygments highlight"><code data-lang="shell"><span></span><span class="tok-nv">TOOLS_POD</span><span class="tok-o">=</span><span class="tok-k">$(</span>oc get pods -n openshift-storage -l <span class="tok-nv">app</span><span class="tok-o">=</span>rook-ceph-tools -o name<span class="tok-k">)</span>
oc rsh -n openshift-storage <span class="tok-nv">$TOOLS_POD</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>Run the same Ceph commands as before the application deployment and compare to results in prior section. Notice the number of objects in <code>ocs-storagecluster-cephblockpool</code> has increased. The third command lists RBDs and we should now have two RBDs.</p>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="pygments highlight"><code data-lang="shell"><span></span>ceph df
rados df
rbd -p ocs-storagecluster-cephblockpool ls <span class="tok-p">|</span> grep vol</code></pre>
</div>
</div>
<div class="paragraph">
<p>You can exit the toolbox by either pressing <span class="keyseq"><kbd>Ctrl</kbd>+<kbd>D</kbd></span> or by executing <code>exit</code>.</p>
</div>
<div class="sect2">
<h3 id="_matching_pvs_to_rbds">3.1. Matching PVs to RBDs</h3>
<div class="paragraph">
<p>A handy way to match persistent volumes to Ceph RBDs is to execute:</p>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="pygments highlight"><code data-lang="shell"><span></span>oc get pv -o <span class="tok-s1">&#39;custom-columns=NAME:.spec.claimRef.name,PVNAME:.metadata.name,STORAGECLASS:.spec.storageClassName,VOLUMEHANDLE:.spec.csi.volumeHandle&#39;</span></code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Example output:</div>
<div class="content">
<pre class="pygments highlight"><code data-lang="shell"><span></span>NAME                      PVNAME                                     STORAGECLASS                  VOLUMEHANDLE
ocs-deviceset-0-0-gzxjb   pvc-1cf104d2-2033-11ea-ac56-0a9ccb4b29e2   gp2                           &lt;none&gt;
ocs-deviceset-1-0-s87xm   pvc-1cf33c42-2033-11ea-ac56-0a9ccb4b29e2   gp2                           &lt;none&gt;
ocs-deviceset-2-0-zcjk4   pvc-1cf4f825-2033-11ea-ac56-0a9ccb4b29e2   gp2                           &lt;none&gt;
db-noobaa-core-0          pvc-3008e684-2033-11ea-a83b-065b3ec3da7c   ocs-storagecluster-ceph-rbd   <span class="tok-m">0001</span>-0011-openshift-storage-0000000000000001-3c0bb177-2033-11ea-9396-0a580a800406
postgresql                pvc-4ca89d3d-2060-11ea-9a42-02dfa51cba90   ocs-storagecluster-ceph-rbd   <span class="tok-m">0001</span>-0011-openshift-storage-0000000000000001-4cbba393-2060-11ea-9396-0a580a800406
rook-ceph-mon-a           pvc-cac661b6-2032-11ea-ac56-0a9ccb4b29e2   gp2                           &lt;none&gt;
rook-ceph-mon-b           pvc-cde2d8b3-2032-11ea-ac56-0a9ccb4b29e2   gp2                           &lt;none&gt;
rook-ceph-mon-c           pvc-d0efbd9d-2032-11ea-ac56-0a9ccb4b29e2   gp2                           &lt;none&gt;
lab-ossm-hub-data         pvc-dc1d4bdc-2028-11ea-ad6c-0a9ccb4b29e2   gp2                           &lt;none&gt;</code></pre>
</div>
</div>
<div class="paragraph">
<p>The second half of the <code>VOLUMEHANDLE</code> column mostly matches what your RBD is named inside of Ceph. All you have to do is append <code>csi-vol-</code> to the front like this:</p>
</div>
<div class="listingblock execute">
<div class="title">Get the full RBD name of our postgreSQL PV in one command</div>
<div class="content">
<pre class="pygments highlight"><code data-lang="shell"><span></span>oc get pv pvc-4ca89d3d-2060-11ea-9a42-02dfa51cba90 -o <span class="tok-nv">jsonpath</span><span class="tok-o">=</span><span class="tok-s1">&#39;{.spec.csi.volumeHandle}&#39;</span> <span class="tok-p">|</span> cut -d <span class="tok-s1">&#39;-&#39;</span> -f <span class="tok-m">6</span>- <span class="tok-p">|</span> awk <span class="tok-s1">&#39;{print &quot;csi-vol-&quot;$1}&#39;</span></code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph">
<p>You will need to adjust the above command to use your <code>PVNAME</code> name</p>
</div>
</td>
</tr>
</table>
</div>
<div class="listingblock">
<div class="title">Example output:</div>
<div class="content">
<pre class="pygments highlight"><code data-lang="shell"><span></span>csi-vol-4cbba393-2060-11ea-9396-0a580a800406</code></pre>
</div>
</div>
<div class="paragraph">
<p>Now we can check on the details of our RBD from inside of the tools pod:</p>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="pygments highlight"><code data-lang="shell"><span></span><span class="tok-nv">TOOLS_POD</span><span class="tok-o">=</span><span class="tok-k">$(</span>oc get pods -n openshift-storage -l <span class="tok-nv">app</span><span class="tok-o">=</span>rook-ceph-tools -o name<span class="tok-k">)</span>
oc rsh -n openshift-storage <span class="tok-nv">$TOOLS_POD</span> rbd -p ocs-storagecluster-cephblockpool info csi-vol-4cbba393-2060-11ea-9396-0a580a800406</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Example output:</div>
<div class="content">
<pre class="pygments highlight"><code data-lang="shell"><span></span>rbd image <span class="tok-s1">&#39;csi-vol-4cbba393-2060-11ea-9396-0a580a800406&#39;</span>:
	size <span class="tok-m">5</span> GiB in <span class="tok-m">1280</span> objects
	order <span class="tok-m">22</span> <span class="tok-o">(</span><span class="tok-m">4</span> MiB objects<span class="tok-o">)</span>
	snapshot_count: <span class="tok-m">0</span>
	id: 95e4f3973e8
	block_name_prefix: rbd_data.95e4f3973e8
	format: <span class="tok-m">2</span>
	features: layering
	op_features:
	flags:
	create_timestamp: Tue Dec <span class="tok-m">17</span> <span class="tok-m">00</span>:00:57 <span class="tok-m">2019</span>
	access_timestamp: Tue Dec <span class="tok-m">17</span> <span class="tok-m">00</span>:00:57 <span class="tok-m">2019</span>
	modify_timestamp: Tue Dec <span class="tok-m">17</span> <span class="tok-m">00</span>:00:57 <span class="tok-m">2019</span></code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph">
<p>You will need to adjust the above command to use your <code>RBD</code> name</p>
</div>
</td>
</tr>
</table>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_create_a_new_ocp_application_deployment_using_cephfs_volume">4. Create a new OCP application deployment using CephFS volume</h2>
<div class="sectionbody">
<div class="paragraph">
<p>In this section the <code>ocs-storagecluster-cephfs</code> <strong>Storage Class</strong> will be used to create a RWX (ReadWriteMany) PVC that can be used by multiple pods at the same time. The application we will use is called <code>File Uploader</code>.</p>
</div>
<div class="paragraph">
<p>Create a new project:</p>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="pygments highlight"><code data-lang="shell"><span></span>oc new-project my-shared-storage</code></pre>
</div>
</div>
<div class="paragraph">
<p>Next deploy the example PHP application called <code>file-uploader</code>:</p>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="pygments highlight"><code data-lang="shell"><span></span>oc new-app openshift/php:7.1~https://github.com/christianh814/openshift-php-upload-demo --name<span class="tok-o">=</span>file-uploader</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Sample Output:</div>
<div class="content">
<pre class="pygments highlight"><code data-lang="shell"><span></span>--&gt; Found image 665111f <span class="tok-o">(</span><span class="tok-m">6</span> days old<span class="tok-o">)</span> in image stream <span class="tok-s2">&quot;openshift/php&quot;</span> under tag <span class="tok-s2">&quot;7.1&quot;</span> <span class="tok-k">for</span> <span class="tok-s2">&quot;openshift/php:7.1&quot;</span>

    Apache <span class="tok-m">2</span>.4 with PHP <span class="tok-m">7</span>.1
    -----------------------
    PHP <span class="tok-m">7</span>.1 available as container is a base platform <span class="tok-k">for</span> building and running various PHP <span class="tok-m">7</span>.1 applications and frameworks. PHP is an HTML-embedded scripting language. PHP attempts to make it easy <span class="tok-k">for</span> developers to write dynamically generated web pages. PHP also offers built-in database integration <span class="tok-k">for</span> several commercial and non-commercial database management systems, so writing a database-enabled webpage with PHP is fairly simple. The most common use of PHP coding is probably as a replacement <span class="tok-k">for</span> CGI scripts.

    Tags: builder, php, php71, rh-php71

    * A <span class="tok-nb">source</span> build using <span class="tok-nb">source</span> code from https://github.com/christianh814/openshift-php-upload-demo will be created
      * The resulting image will be pushed to image stream tag <span class="tok-s2">&quot;file-uploader:latest&quot;</span>
      * Use <span class="tok-s1">&#39;oc start-build&#39;</span> to trigger a new build
    * This image will be deployed in deployment config <span class="tok-s2">&quot;file-uploader&quot;</span>
    * Ports <span class="tok-m">8080</span>/tcp, <span class="tok-m">8443</span>/tcp will be load balanced by service <span class="tok-s2">&quot;file-uploader&quot;</span>
      * Other containers can access this service through the hostname <span class="tok-s2">&quot;file-uploader&quot;</span>

--&gt; Creating resources ...
    imagestream.image.openshift.io <span class="tok-s2">&quot;file-uploader&quot;</span> created
    buildconfig.build.openshift.io <span class="tok-s2">&quot;file-uploader&quot;</span> created
    deploymentconfig.apps.openshift.io <span class="tok-s2">&quot;file-uploader&quot;</span> created
    service <span class="tok-s2">&quot;file-uploader&quot;</span> created
--&gt; Success
    Build scheduled, use <span class="tok-s1">&#39;oc logs -f bc/file-uploader&#39;</span> to track its progress.
    Application is not exposed. You can expose services to the outside world by executing one or more of the commands below:
     <span class="tok-s1">&#39;oc expose svc/file-uploader&#39;</span>
    Run <span class="tok-s1">&#39;oc status&#39;</span> to view your app.</code></pre>
</div>
</div>
<div class="paragraph">
<p>Watch and wait for the application to be deployed:</p>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="pygments highlight"><code data-lang="shell"><span></span>oc logs -f bc/file-uploader -n my-shared-storage</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Sample Output:</div>
<div class="content">
<pre class="pygments highlight"><code data-lang="shell"><span></span>Cloning <span class="tok-s2">&quot;https://github.com/christianh814/openshift-php-upload-demo&quot;</span> ...

<span class="tok-o">[</span>...<span class="tok-o">]</span>

Generating dockerfile with builder image image-registry.openshift-image-registry.svc:5000/openshift/php@sha256:a06311381a15078be4d67cf844ba808e688dfe25305c6a696a19aee9b93c72d5
STEP <span class="tok-m">1</span>: FROM image-registry.openshift-image-registry.svc:5000/openshift/php@sha256:a06311381a15078be4d67cf844ba808e688dfe25305c6a696a19aee9b93c72d5
STEP <span class="tok-m">2</span>: LABEL <span class="tok-s2">&quot;io.openshift.build.source-location&quot;</span><span class="tok-o">=</span><span class="tok-s2">&quot;https://github.com/christianh814/openshift-php-upload-demo&quot;</span> <span class="tok-s2">&quot;io.openshift.build.image&quot;</span><span class="tok-o">=</span><span class="tok-s2">&quot;image-registry.openshift-image-registry.svc:5000/openshift/php@sha256:a06311381a15078be4d67cf844ba808e688dfe25305c6a696a19aee9b93c72d5&quot;</span> <span class="tok-s2">&quot;io.openshift.build.commit.author&quot;</span><span class="tok-o">=</span><span class="tok-s2">&quot;Christian Hernandez &lt;christian.hernandez@yahoo.com&gt;&quot;</span> <span class="tok-s2">&quot;io.openshift.build.commit.date&quot;</span><span class="tok-o">=</span><span class="tok-s2">&quot;Sun Oct 1 17:15:09 2017 -0700&quot;</span> <span class="tok-s2">&quot;io.openshift.build.commit.id&quot;</span><span class="tok-o">=</span><span class="tok-s2">&quot;288eda3dff43b02f7f7b6b6b6f93396ffdf34cb2&quot;</span> <span class="tok-s2">&quot;io.openshift.build.commit.ref&quot;</span><span class="tok-o">=</span><span class="tok-s2">&quot;master&quot;</span> <span class="tok-s2">&quot;io.openshift.build.commit.message&quot;</span><span class="tok-o">=</span><span class="tok-s2">&quot;trying to modularize&quot;</span>
STEP <span class="tok-m">3</span>: ENV <span class="tok-nv">OPENSHIFT_BUILD_NAME</span><span class="tok-o">=</span><span class="tok-s2">&quot;file-uploader-1&quot;</span> <span class="tok-nv">OPENSHIFT_BUILD_NAMESPACE</span><span class="tok-o">=</span><span class="tok-s2">&quot;my-shared-storage&quot;</span> <span class="tok-nv">OPENSHIFT_BUILD_SOURCE</span><span class="tok-o">=</span><span class="tok-s2">&quot;https://github.com/christianh814/openshift-php-upload-demo&quot;</span> <span class="tok-nv">OPENSHIFT_BUILD_COMMIT</span><span class="tok-o">=</span><span class="tok-s2">&quot;288eda3dff43b02f7f7b6b6b6f93396ffdf34cb2&quot;</span>
STEP <span class="tok-m">4</span>: USER root
STEP <span class="tok-m">5</span>: COPY upload/src /tmp/src
STEP <span class="tok-m">6</span>: RUN chown -R <span class="tok-m">1001</span>:0 /tmp/src
<span class="tok-nv">time</span><span class="tok-o">=</span><span class="tok-s2">&quot;2019-11-20T18:53:16Z&quot;</span> <span class="tok-nv">level</span><span class="tok-o">=</span>warning <span class="tok-nv">msg</span><span class="tok-o">=</span><span class="tok-s2">&quot;pkg/chroot: error unmounting \&quot;/tmp/buildah873160532/mnt/rootfs\&quot;: error checking if \&quot;/tmp/buildah873160532/mnt/rootfs/sys/fs/cgroup/memory\&quot; is mounted: no such file or directory&quot;</span>
<span class="tok-nv">time</span><span class="tok-o">=</span><span class="tok-s2">&quot;2019-11-20T18:53:16Z&quot;</span> <span class="tok-nv">level</span><span class="tok-o">=</span>warning <span class="tok-nv">msg</span><span class="tok-o">=</span><span class="tok-s2">&quot;pkg/bind: error unmounting \&quot;/tmp/buildah873160532/mnt/rootfs\&quot;: error checking if \&quot;/tmp/buildah873160532/mnt/rootfs/sys/fs/cgroup/memory\&quot; is mounted: no such file or directory&quot;</span>
STEP <span class="tok-m">7</span>: USER <span class="tok-m">1001</span>
STEP <span class="tok-m">8</span>: RUN /usr/libexec/s2i/assemble
---&gt; Installing application source...
<span class="tok-o">=</span>&gt; sourcing <span class="tok-m">20</span>-copy-config.sh ...
---&gt; <span class="tok-m">18</span>:53:16     Processing additional arbitrary httpd configuration provided by s2i ...
<span class="tok-o">=</span>&gt; sourcing <span class="tok-m">00</span>-documentroot.conf ...
<span class="tok-o">=</span>&gt; sourcing <span class="tok-m">50</span>-mpm-tuning.conf ...
<span class="tok-o">=</span>&gt; sourcing <span class="tok-m">40</span>-ssl-certs.sh ...
<span class="tok-nv">time</span><span class="tok-o">=</span><span class="tok-s2">&quot;2019-11-20T18:53:17Z&quot;</span> <span class="tok-nv">level</span><span class="tok-o">=</span>warning <span class="tok-nv">msg</span><span class="tok-o">=</span><span class="tok-s2">&quot;pkg/chroot: error unmounting \&quot;/tmp/buildah357283409/mnt/rootfs\&quot;: error checking if \&quot;/tmp/buildah357283409/mnt/rootfs/sys/fs/cgroup/memory\&quot; is mounted: no such file or directory&quot;</span>
<span class="tok-nv">time</span><span class="tok-o">=</span><span class="tok-s2">&quot;2019-11-20T18:53:17Z&quot;</span> <span class="tok-nv">level</span><span class="tok-o">=</span>warning <span class="tok-nv">msg</span><span class="tok-o">=</span><span class="tok-s2">&quot;pkg/bind: error unmounting \&quot;/tmp/buildah357283409/mnt/rootfs\&quot;: error checking if \&quot;/tmp/buildah357283409/mnt/rootfs/sys/fs/cgroup/memory\&quot; is mounted: no such file or directory&quot;</span>
STEP <span class="tok-m">9</span>: CMD /usr/libexec/s2i/run
STEP <span class="tok-m">10</span>: COMMIT temp.builder.openshift.io/my-shared-storage/file-uploader-1:562d8fb3
Getting image <span class="tok-nb">source</span> signatures

<span class="tok-o">[</span>...<span class="tok-o">]</span>

Writing manifest to image destination
Storing signatures
Successfully pushed image-registry.openshift-image-registry.svc:5000/my-shared-storage/file-uploader@sha256:74029bb63e4b7cb33602eb037d45d3d27245ffbfc105fd2a4587037c6b063183
Push successful</code></pre>
</div>
</div>
<div class="paragraph">
<p>The command prompt returns out of the tail mode once you see <em>Push successful</em>.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph">
<p>This use of the <code>new-app</code> command directly asked for application code to be
built and did not involve a template. That&#8217;s why it only created a <strong>single
Pod</strong> deployment with a <strong>Service</strong> and no <strong>Route</strong>.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Let&#8217;s make our application production ready by exposing it via a <code>Route</code> and scale to 3 instances for high availability:</p>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="pygments highlight"><code data-lang="shell"><span></span>oc expose svc/file-uploader -n my-shared-storage</code></pre>
</div>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="pygments highlight"><code data-lang="shell"><span></span>oc scale --replicas<span class="tok-o">=</span><span class="tok-m">3</span> dc/file-uploader -n my-shared-storage</code></pre>
</div>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="pygments highlight"><code data-lang="shell"><span></span>oc get pods -n my-shared-storage</code></pre>
</div>
</div>
<div class="paragraph">
<p>You should have 3 <code>file-uploader</code> <strong>Pods</strong> in a few minutes.</p>
</div>
<div class="admonitionblock caution">
<table>
<tr>
<td class="icon">
<i class="fa icon-caution" title="Caution"></i>
</td>
<td class="content">
<div class="paragraph">
<p>Never attempt to store persistent data in a <strong>Pod</strong> that has no persistent
volume associated with it. <strong>Pods</strong> and their containers are ephemeral by
definition, and any stored data will be lost as soon as the <strong>Pod</strong> terminates
for whatever reason.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>The app is of course not useful like this. We can fix this by providing shared
storage to this app.</p>
</div>
<div class="paragraph">
<p>You can create a <strong>PersistentVolumeClaim</strong> and attach it into an application with
the <code>oc set volume</code> command. Execute the following</p>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="pygments highlight"><code data-lang="shell"><span></span>oc <span class="tok-nb">set</span> volume dc/file-uploader --add --name<span class="tok-o">=</span>my-shared-storage <span class="tok-se">\</span>
-t pvc --claim-mode<span class="tok-o">=</span>ReadWriteMany --claim-size<span class="tok-o">=</span>1Gi <span class="tok-se">\</span>
--claim-name<span class="tok-o">=</span>my-shared-storage --claim-class<span class="tok-o">=</span>ocs-storagecluster-cephfs <span class="tok-se">\</span>
--mount-path<span class="tok-o">=</span>/opt/app-root/src/uploaded <span class="tok-se">\</span>
-n my-shared-storage</code></pre>
</div>
</div>
<div class="paragraph">
<p>This command will:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>create a <strong>PersistentVolumeClaim</strong></p>
</li>
<li>
<p>update the <strong>DeploymentConfig</strong> to include a <code>volume</code> definition</p>
</li>
<li>
<p>update the <strong>DeploymentConfig</strong> to attach a <code>volumemount</code> into the specified
<code>mount-path</code></p>
</li>
<li>
<p>cause a new deployment of the 3 application <strong>Pods</strong></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>For more information on what <code>oc set volume</code> is capable of, look at its help output
with <code>oc set volume -h</code>. Now, let&#8217;s look at the result of adding the volume:</p>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="pygments highlight"><code data-lang="shell"><span></span>oc get pvc -n my-shared-storage</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Sample Output:</div>
<div class="content">
<pre class="pygments highlight"><code data-lang="shell"><span></span>NAME                STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS                AGE
my-shared-storage   Bound    pvc-371c2184-fb73-11e9-b901-0aad1a53052d   1Gi        RWX            ocs-storagecluster-cephfs   47s</code></pre>
</div>
</div>
<div class="paragraph">
<p>Notice the <code>ACCESSMODE</code> being set to <strong>RWX</strong> (short for <code>ReadWriteMany</code>).</p>
</div>
<div class="paragraph">
<p>All 3 <code>file-uploader</code><strong>Pods</strong> are using the same <strong>RWX</strong> volume. Without this <code>ACCESSMODE</code>, OpenShift will not attempt to attach multiple <strong>Pods</strong> to the same <strong>PersistentVolume</strong>
reliably. If you attempt to scale up deployments that are using <strong>RWO</strong> or <code>ReadWriteOnce</code> storage, the <strong>Pods</strong> will actually all become co-located on the same
node.</p>
</div>
<div class="paragraph">
<p>Try it out in your file uploader web application using your browser. Upload
new files.</p>
</div>
<div class="paragraph">
<p>Now, check the <strong>Route</strong> that has been created:</p>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="pygments highlight"><code data-lang="shell"><span></span>oc get route file-uploader -n my-shared-storage -o jsonpath --template<span class="tok-o">=</span><span class="tok-s2">&quot;{.spec.host}&quot;</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>This will return a route similar to this one (careful: there is no line break at the end so your shell prompt appears right after the output).</p>
</div>
<div class="listingblock">
<div class="title">Sample Output:</div>
<div class="content">
<pre class="pygments highlight"><code data-lang="shell"><span></span>file-uploader-my-shared-storage.apps.cluster-ocs-9b06.ocs-9b06.example.opentlc.com</code></pre>
</div>
</div>
<div class="paragraph">
<p>Point your browser to the web application using the URL advertised by your route. <strong>Your <code>route</code> will be different</strong></p>
</div>
<div class="paragraph">
<p>The web app simply lists all uploaded files and offers the ability to upload new ones as well as download the existing data. Right now there is
nothing.</p>
</div>
<div class="paragraph">
<p>Select an arbitrary file from your local machine and upload it to the app.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/ocs/uploader_screen_upload.png" alt="uploader screen upload">
</div>
<div class="title">Figure 13. A simple PHP-based file upload tool</div>
</div>
<div class="paragraph">
<p>Once done click <strong><em>List uploaded files</em></strong> to see the list of all currently
uploaded files.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_using_ocs_for_prometheus_metrics">5. Using OCS for Prometheus Metrics</h2>
<div class="sectionbody">
<div class="paragraph">
<p>OpenShift ships with a pre-configured and self-updating monitoring stack that is based on the Prometheus open source project and its wider eco-system. It provides monitoring of cluster components and ships with a set of alerts to immediately notify the cluster administrator about any occurring problems.</p>
</div>
<div class="paragraph">
<p>For production environments, it is highly recommended to configure persistent storage using block storage technology. OCS 4 provide block storage using Ceph RBD volumes. Running cluster monitoring with persistent storage means that your metrics are stored to a persistent volume and can survive a pod being restarted or recreated. This is ideal if you require your metrics or alerting data to be guarded from data loss. For production environments, it is highly recommended to configure persistent storage using block storage technology. OCS 4 provide block storage using Ceph RBD volumes. The following instructions will detail how to migrate Prometheus and Alertmanager storage to Ceph RBD volumes for persistence.</p>
</div>
<div class="paragraph">
<p>First, let&#8217;s discover what <strong>Pods</strong> and <strong>PVCs</strong> are installed in the <code>openshift-monitoring</code> namespace.</p>
</div>
<div class="paragraph">
<p>In the prior module, OpenShift Infrastructure Nodes, the Prometheus and AlertManager resources were moved to the OCP infra nodes.</p>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="pygments highlight"><code data-lang="shell"><span></span>oc get pods,pvc -n openshift-monitoring</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Example output:</div>
<div class="content">
<pre class="pygments highlight"><code data-lang="shell"><span></span>NAME                                               READY   STATUS    RESTARTS   AGE
pod/alertmanager-main-0                            <span class="tok-m">3</span>/3     Running   <span class="tok-m">0</span>          6d23h
pod/alertmanager-main-1                            <span class="tok-m">3</span>/3     Running   <span class="tok-m">0</span>          6d23h
pod/alertmanager-main-2                            <span class="tok-m">3</span>/3     Running   <span class="tok-m">0</span>          6d23h
pod/cluster-monitoring-operator-84cd9df668-74wnk   <span class="tok-m">1</span>/1     Running   <span class="tok-m">0</span>          6d23h
pod/grafana-5db6fd97f8-fqj5g                       <span class="tok-m">2</span>/2     Running   <span class="tok-m">0</span>          6d23h
pod/kube-state-metrics-895899678-pm8h7             <span class="tok-m">3</span>/3     Running   <span class="tok-m">0</span>          6d23h
pod/node-exporter-69hqs                            <span class="tok-m">2</span>/2     Running   <span class="tok-m">0</span>          6d23h
pod/node-exporter-mw7lf                            <span class="tok-m">2</span>/2     Running   <span class="tok-m">0</span>          6d23h
pod/node-exporter-npngl                            <span class="tok-m">2</span>/2     Running   <span class="tok-m">0</span>          6d23h
pod/node-exporter-p8nv7                            <span class="tok-m">2</span>/2     Running   <span class="tok-m">0</span>          6d23h
pod/node-exporter-pgppl                            <span class="tok-m">2</span>/2     Running   <span class="tok-m">0</span>          6d23h
pod/node-exporter-pnnhb                            <span class="tok-m">2</span>/2     Running   <span class="tok-m">0</span>          6d23h
pod/node-exporter-rb4wv                            <span class="tok-m">2</span>/2     Running   <span class="tok-m">0</span>          6d23h
pod/node-exporter-rwpwj                            <span class="tok-m">2</span>/2     Running   <span class="tok-m">0</span>          6d23h
pod/node-exporter-xpvv7                            <span class="tok-m">2</span>/2     Running   <span class="tok-m">0</span>          6d23h
pod/openshift-state-metrics-77d5f699d8-km8dn       <span class="tok-m">3</span>/3     Running   <span class="tok-m">0</span>          6d23h
pod/prometheus-adapter-7cd7578f49-2wr84            <span class="tok-m">1</span>/1     Running   <span class="tok-m">0</span>          5d23h
pod/prometheus-adapter-7cd7578f49-hbwgg            <span class="tok-m">1</span>/1     Running   <span class="tok-m">0</span>          5d23h
pod/prometheus-k8s-0                               <span class="tok-m">6</span>/6     Running   <span class="tok-m">1</span>          6d23h
pod/prometheus-k8s-1                               <span class="tok-m">6</span>/6     Running   <span class="tok-m">1</span>          6d23h
pod/prometheus-operator-cbfd89f9-95bgj             <span class="tok-m">1</span>/1     Running   <span class="tok-m">0</span>          156m
pod/telemeter-client-7c65855db4-vd5jl              <span class="tok-m">3</span>/3     Running   <span class="tok-m">0</span>          6d23h</code></pre>
</div>
</div>
<div class="paragraph">
<p>At this point there are no <strong>PVC</strong> resources because Prometheus and AlertManager are both using ephemeral (EmptyDir) storage. This is the way OpenShift is initially installed. The Prometheus stack consists of the Prometheus database and the alertmanager data. Persisting both is best-practice since data loss on either of these will cause you to lose your collected metrics and alerting data.</p>
</div>
<div class="sect2">
<h3 id="_modifying_your_prometheus_environment">5.1. Modifying your Prometheus environment</h3>
<div class="paragraph">
<p>For Prometheus every supported configuration change is controlled through a central <strong>ConfigMap</strong>, which needs to exist before we can make changes. When you start off with a clean installation of Openshift, the ConfigMap to configure the Prometheus environment may not be present. To check if your ConfigMap is present, execute this:</p>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="pygments highlight"><code data-lang="shell"><span></span>oc -n openshift-monitoring get configmap cluster-monitoring-config</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Output if the ConfigMap is not yet created:</div>
<div class="content">
<pre class="pygments highlight"><code data-lang="shell"><span></span>Error from server <span class="tok-o">(</span>NotFound<span class="tok-o">)</span>: configmaps <span class="tok-s2">&quot;cluster-monitoring-config&quot;</span> not found</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Output if the ConfigMap is created:</div>
<div class="content">
<pre class="pygments highlight"><code data-lang="shell"><span></span>NAME                        DATA   AGE
cluster-monitoring-config   <span class="tok-m">1</span>      116m</code></pre>
</div>
</div>
<div class="paragraph">
<p>If you are missing the <strong>ConfigMap</strong>, create it using this command:</p>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="pygments highlight"><code data-lang="shell"><span></span>oc apply <span class="tok-o">{{</span> HOME_PATH <span class="tok-o">}}</span>/support/ocslab_cluster-monitoring-noinfra.yaml</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Sample output:</div>
<div class="content">
<pre class="pygments highlight"><code data-lang="shell"><span></span>configmap/cluster-monitoring-config created</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph">
<p>If the <strong>ConfigMap</strong> already exists because of completing prior module <code>OpenShift Infrastructure Nodes</code>, you will apply changes to the existing <strong>ConfigMap</strong>.</p>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="pygments highlight"><code data-lang="shell"><span></span>oc apply <span class="tok-o">{{</span> HOME_PATH <span class="tok-o">}}</span>/support/ocslab_cluster-monitoring-withinfra.yaml</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Sample output:</div>
<div class="content">
<pre class="pygments highlight"><code data-lang="shell"><span></span>configmap/cluster-monitoring-config updated</code></pre>
</div>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>You can view the <strong>ConfigMap</strong> with the following command:</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
The size of the Ceph RBD volumes, <code>40Gi</code>, can be modified to be larger or smaller depending on requirements.
</td>
</tr>
</table>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="pygments highlight"><code data-lang="shell"><span></span>oc -n openshift-monitoring get configmap cluster-monitoring-config -o yaml</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">ConfigMap sample output:</div>
<div class="content">
<pre class="pygments highlight"><code data-lang="yaml"><span></span><span class="tok-nn">...</span>
      <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">volumeClaimTemplate</span><span class="tok-p tok-p-Indicator">:</span>
        <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">metadata</span><span class="tok-p tok-p-Indicator">:</span>
          <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">name</span><span class="tok-p tok-p-Indicator">:</span> <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">prometheusdb</span>
        <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">spec</span><span class="tok-p tok-p-Indicator">:</span>
          <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">storageClassName</span><span class="tok-p tok-p-Indicator">:</span> <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">ocs-storagecluster-ceph-rbd</span>
          <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">resources</span><span class="tok-p tok-p-Indicator">:</span>
            <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">requests</span><span class="tok-p tok-p-Indicator">:</span>
              <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">storage</span><span class="tok-p tok-p-Indicator">:</span> <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">40Gi</span>
<span class="tok-nn">...</span>
      <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">volumeClaimTemplate</span><span class="tok-p tok-p-Indicator">:</span>
        <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">metadata</span><span class="tok-p tok-p-Indicator">:</span>
          <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">name</span><span class="tok-p tok-p-Indicator">:</span> <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">alertmanager</span>
        <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">spec</span><span class="tok-p tok-p-Indicator">:</span>
          <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">storageClassName</span><span class="tok-p tok-p-Indicator">:</span> <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">ocs-storagecluster-ceph-rbd</span>
          <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">resources</span><span class="tok-p tok-p-Indicator">:</span>
            <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">requests</span><span class="tok-p tok-p-Indicator">:</span>
              <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">storage</span><span class="tok-p tok-p-Indicator">:</span> <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">40Gi</span>
<span class="tok-nn">...</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>Once you create this new <strong>ConfigMap</strong> <code>cluster-monitoring-config</code>, the affected <strong>Pods</strong> will automatically be restarted and the new storage will be mounted in the Pods.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph">
<p>It is not possible to retain data that was written on the default EmptyDir-based or ephemeral installation. Thus you will start with an empty DB after changing the backend storage thereby starting over with metric collection and reporting.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>After a couple of minutes, the AlertManager and Prometheus <strong>Pods</strong> will have restarted and you will see new <strong>PVCs</strong> in the <code>openshift-monitoring</code> namespace that they are now providing persistent storage.</p>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="pygments highlight"><code data-lang="shell"><span></span>oc get pods,pvc -n openshift-monitoring</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Example output:</div>
<div class="content">
<pre class="pygments highlight"><code data-lang="yaml"><span></span><span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">NAME                               STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS                  AGE</span>
<span class="tok-nn">...</span>
<span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">alertmanager-alertmanager-main-0   Bound    pvc-733be285-aaf9-4334-9662-44b63bb4efdf   40Gi       RWO            ocs-storagecluster-ceph-rbd   3m37s</span>
<span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">alertmanager-alertmanager-main-1   Bound    pvc-e07ebe61-de5d-404c-9a25-bb3a677281c5   40Gi       RWO            ocs-storagecluster-ceph-rbd   3m37s</span>
<span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">alertmanager-alertmanager-main-2   Bound    pvc-9de2edf2-9f5e-4f62-8aa7-ecfd01957748   40Gi       RWO            ocs-storagecluster-ceph-rbd   3m37s</span>
<span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">prometheusdb-prometheus-k8s-0      Bound    pvc-5b845908-d929-4326-976e-0659901468e9   40Gi       RWO            ocs-storagecluster-ceph-rbd   3m31s</span>
<span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">prometheusdb-prometheus-k8s-1      Bound    pvc-f2d22176-6348-451f-9ede-c00b303339af   40Gi       RWO            ocs-storagecluster-ceph-rbd   3m31s</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>You can validate that Prometheus and AlertManager are working correctly after moving to persistent storage <a href="#_monitoring_the_ocs_environment">in a later section</a> of this lab guide.</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_using_the_multi_cloud_gateway">6. Using the Multi-Cloud-Gateway</h2>
<div class="sectionbody">
<div class="paragraph">
<p>This section discusses the usage of the Multi-Cloud-Gateway (MCG). Currently the best way to configure the MCG is to use the CLI.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
While the NooBaa Web Management Console is accessible, it should not be used to create any resources, since they are currently not synchronized back to the Openshift cluster.
</td>
</tr>
</table>
</div>
<div class="sect2">
<h3 id="_checking_on_the_mcg_status">6.1. Checking on the MCG status</h3>
<div class="paragraph">
<p>The MCG status can be checked with the NooBaa CLI. Make sure you are in the <code>openshift-storage</code> project when you execute this command.</p>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="pygments highlight"><code data-lang="shell"><span></span>noobaa status -n openshift-storage</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Example output:</div>
<div class="content">
<pre class="pygments highlight"><code data-lang="shell"><span></span>INFO<span class="tok-o">[</span><span class="tok-m">0000</span><span class="tok-o">]</span> CLI version: <span class="tok-m">2</span>.0.9
INFO<span class="tok-o">[</span><span class="tok-m">0000</span><span class="tok-o">]</span> noobaa-image: noobaa/noobaa-core:5.2.11
INFO<span class="tok-o">[</span><span class="tok-m">0000</span><span class="tok-o">]</span> operator-image: noobaa/noobaa-operator:2.0.9
INFO<span class="tok-o">[</span><span class="tok-m">0000</span><span class="tok-o">]</span> Namespace: openshift-storage
INFO<span class="tok-o">[</span><span class="tok-m">0000</span><span class="tok-o">]</span>
INFO<span class="tok-o">[</span><span class="tok-m">0000</span><span class="tok-o">]</span> CRD Status:
INFO<span class="tok-o">[</span><span class="tok-m">0000</span><span class="tok-o">]</span>  Exists: CustomResourceDefinition <span class="tok-s2">&quot;noobaas.noobaa.io&quot;</span>
INFO<span class="tok-o">[</span><span class="tok-m">0001</span><span class="tok-o">]</span>  Exists: CustomResourceDefinition <span class="tok-s2">&quot;backingstores.noobaa.io&quot;</span>
INFO<span class="tok-o">[</span><span class="tok-m">0001</span><span class="tok-o">]</span>  Exists: CustomResourceDefinition <span class="tok-s2">&quot;bucketclasses.noobaa.io&quot;</span>
INFO<span class="tok-o">[</span><span class="tok-m">0001</span><span class="tok-o">]</span>  Exists: CustomResourceDefinition <span class="tok-s2">&quot;objectbucketclaims.objectbucket.io&quot;</span>
INFO<span class="tok-o">[</span><span class="tok-m">0001</span><span class="tok-o">]</span>  Exists: CustomResourceDefinition <span class="tok-s2">&quot;objectbuckets.objectbucket.io&quot;</span>
INFO<span class="tok-o">[</span><span class="tok-m">0001</span><span class="tok-o">]</span>
INFO<span class="tok-o">[</span><span class="tok-m">0001</span><span class="tok-o">]</span> Operator Status:
INFO<span class="tok-o">[</span><span class="tok-m">0001</span><span class="tok-o">]</span>  Exists: Namespace <span class="tok-s2">&quot;openshift-storage&quot;</span>
INFO<span class="tok-o">[</span><span class="tok-m">0001</span><span class="tok-o">]</span>  Exists: ServiceAccount <span class="tok-s2">&quot;noobaa&quot;</span>
INFO<span class="tok-o">[</span><span class="tok-m">0001</span><span class="tok-o">]</span>  Exists: Role <span class="tok-s2">&quot;ocs-operator.v0.0.273-l5jqf&quot;</span>
INFO<span class="tok-o">[</span><span class="tok-m">0001</span><span class="tok-o">]</span>  Exists: RoleBinding <span class="tok-s2">&quot;ocs-operator.v0.0.273-l5jqf-noobaa-s4vrx&quot;</span>
INFO<span class="tok-o">[</span><span class="tok-m">0002</span><span class="tok-o">]</span>  Exists: ClusterRole <span class="tok-s2">&quot;ocs-operator.v0.0.273-k4j99&quot;</span>
INFO<span class="tok-o">[</span><span class="tok-m">0002</span><span class="tok-o">]</span>  Exists: ClusterRoleBinding <span class="tok-s2">&quot;ocs-operator.v0.0.273-k4j99-noobaa-6hcbk&quot;</span>
INFO<span class="tok-o">[</span><span class="tok-m">0002</span><span class="tok-o">]</span>  Exists: Deployment <span class="tok-s2">&quot;noobaa-operator&quot;</span>
INFO<span class="tok-o">[</span><span class="tok-m">0002</span><span class="tok-o">]</span>
INFO<span class="tok-o">[</span><span class="tok-m">0002</span><span class="tok-o">]</span> System Status:
INFO<span class="tok-o">[</span><span class="tok-m">0002</span><span class="tok-o">]</span>  Exists: NooBaa <span class="tok-s2">&quot;noobaa&quot;</span>
INFO<span class="tok-o">[</span><span class="tok-m">0002</span><span class="tok-o">]</span>  Exists: StatefulSet <span class="tok-s2">&quot;noobaa-core&quot;</span>
INFO<span class="tok-o">[</span><span class="tok-m">0002</span><span class="tok-o">]</span>  Exists: Service <span class="tok-s2">&quot;noobaa-mgmt&quot;</span>
INFO<span class="tok-o">[</span><span class="tok-m">0002</span><span class="tok-o">]</span>  Exists: Service <span class="tok-s2">&quot;s3&quot;</span>
INFO<span class="tok-o">[</span><span class="tok-m">0002</span><span class="tok-o">]</span>  Exists: Secret <span class="tok-s2">&quot;noobaa-server&quot;</span>
INFO<span class="tok-o">[</span><span class="tok-m">0002</span><span class="tok-o">]</span>  Exists: Secret <span class="tok-s2">&quot;noobaa-operator&quot;</span>
INFO<span class="tok-o">[</span><span class="tok-m">0002</span><span class="tok-o">]</span>  Exists: Secret <span class="tok-s2">&quot;noobaa-admin&quot;</span>
INFO<span class="tok-o">[</span><span class="tok-m">0003</span><span class="tok-o">]</span>  Exists: StorageClass <span class="tok-s2">&quot;openshift-storage.noobaa.io&quot;</span>
INFO<span class="tok-o">[</span><span class="tok-m">0003</span><span class="tok-o">]</span>  Exists: BucketClass <span class="tok-s2">&quot;noobaa-default-bucket-class&quot;</span>
INFO<span class="tok-o">[</span><span class="tok-m">0003</span><span class="tok-o">]</span>  <span class="tok-o">(</span>Optional<span class="tok-o">)</span> Exists: BackingStore <span class="tok-s2">&quot;noobaa-default-backing-store&quot;</span>
INFO<span class="tok-o">[</span><span class="tok-m">0003</span><span class="tok-o">]</span>  <span class="tok-o">(</span>Optional<span class="tok-o">)</span> Exists: CredentialsRequest <span class="tok-s2">&quot;noobaa-cloud-creds&quot;</span>
INFO<span class="tok-o">[</span><span class="tok-m">0003</span><span class="tok-o">]</span>  <span class="tok-o">(</span>Optional<span class="tok-o">)</span> Exists: PrometheusRule <span class="tok-s2">&quot;noobaa-prometheus-rules&quot;</span>
INFO<span class="tok-o">[</span><span class="tok-m">0003</span><span class="tok-o">]</span>  <span class="tok-o">(</span>Optional<span class="tok-o">)</span> Exists: ServiceMonitor <span class="tok-s2">&quot;noobaa-service-monitor&quot;</span>
INFO<span class="tok-o">[</span><span class="tok-m">0003</span><span class="tok-o">]</span>  <span class="tok-o">(</span>Optional<span class="tok-o">)</span> Exists: Route <span class="tok-s2">&quot;noobaa-mgmt&quot;</span>
INFO<span class="tok-o">[</span><span class="tok-m">0003</span><span class="tok-o">]</span>  <span class="tok-o">(</span>Optional<span class="tok-o">)</span> Exists: Route <span class="tok-s2">&quot;s3&quot;</span>
INFO<span class="tok-o">[</span><span class="tok-m">0003</span><span class="tok-o">]</span>  Exists: PersistentVolumeClaim <span class="tok-s2">&quot;db-noobaa-core-0&quot;</span>
INFO<span class="tok-o">[</span><span class="tok-m">0003</span><span class="tok-o">]</span>  System Phase is <span class="tok-s2">&quot;Ready&quot;</span>
INFO<span class="tok-o">[</span><span class="tok-m">0003</span><span class="tok-o">]</span>  Exists:  <span class="tok-s2">&quot;noobaa-admin&quot;</span>

<span class="tok-c1">#------------------#</span>
<span class="tok-c1">#- Mgmt Addresses -#</span>
<span class="tok-c1">#------------------#</span>

ExternalDNS : <span class="tok-o">[</span>https://noobaa-mgmt-openshift-storage.apps.cluster-ocs-18dd.ocs-18dd.example.opentlc.com https://aa9e6c341187a11ea8e670a863dc4c4d-1226242861.us-east-1.elb.amazonaws.com:443<span class="tok-o">]</span>
ExternalIP  : <span class="tok-o">[]</span>
NodePorts   : <span class="tok-o">[</span>https://10.0.157.178:31811<span class="tok-o">]</span>
InternalDNS : <span class="tok-o">[</span>https://noobaa-mgmt.openshift-storage.svc:443<span class="tok-o">]</span>
InternalIP  : <span class="tok-o">[</span>https://172.30.212.225:443<span class="tok-o">]</span>
PodPorts    : <span class="tok-o">[</span>https://10.130.2.10:8443<span class="tok-o">]</span>

<span class="tok-c1">#--------------------#</span>
<span class="tok-c1">#- Mgmt Credentials -#</span>
<span class="tok-c1">#--------------------#</span>

email    : admin@noobaa.io
password : 5Iqq3+XoZS/sPWTkD2c5Aw<span class="tok-o">==</span>

<span class="tok-c1">#----------------#</span>
<span class="tok-c1">#- S3 Addresses -#</span>
<span class="tok-c1">#----------------#</span>

ExternalDNS : <span class="tok-o">[</span>https://s3-openshift-storage.apps.cluster-ocs-18dd.ocs-18dd.example.opentlc.com https://aa9f0fa4b187a11ea8e670a863dc4c4d-390690077.us-east-1.elb.amazonaws.com:443<span class="tok-o">]</span>
ExternalIP  : <span class="tok-o">[]</span>
NodePorts   : <span class="tok-o">[</span>https://10.0.157.178:31605<span class="tok-o">]</span>
InternalDNS : <span class="tok-o">[</span>https://s3.openshift-storage.svc:443<span class="tok-o">]</span>
InternalIP  : <span class="tok-o">[</span>https://172.30.252.169:443<span class="tok-o">]</span>
PodPorts    : <span class="tok-o">[</span>https://10.130.2.10:6443<span class="tok-o">]</span>

<span class="tok-c1">#------------------#</span>
<span class="tok-c1">#- S3 Credentials -#</span>
<span class="tok-c1">#------------------#</span>

AWS_ACCESS_KEY_ID     : rQNcbCCIGxkApCA3U8TB
AWS_SECRET_ACCESS_KEY : V9qxglxRrJETkmEFBo04aWYu8Jpp6IBMS9w73fQr

<span class="tok-c1">#------------------#</span>
<span class="tok-c1">#- Backing Stores -#</span>
<span class="tok-c1">#------------------#</span>

NAME                           TYPE     TARGET-BUCKET                                               PHASE   AGE
noobaa-default-backing-store   aws-s3   noobaa-backing-store-0b438b35-023f-4ce4-99e5-557f88c210b0   Ready   1h39m31s

<span class="tok-c1">#------------------#</span>
<span class="tok-c1">#- Bucket Classes -#</span>
<span class="tok-c1">#------------------#</span>

NAME                          PLACEMENT                                                             PHASE   AGE
noobaa-default-bucket-class   <span class="tok-o">{</span>Tiers:<span class="tok-o">[{</span>Placement: BackingStores:<span class="tok-o">[</span>noobaa-default-backing-store<span class="tok-o">]}]}</span>   Ready   1h39m31s

<span class="tok-c1">#-----------------#</span>
<span class="tok-c1">#- Bucket Claims -#</span>
<span class="tok-c1">#-----------------#</span>

No OBC<span class="tok-err">&#39;</span>s found.</code></pre>
</div>
</div>
<div class="paragraph">
<p>As you can see - the NooBaa CLI will first check on the environment and will then print all the information about the environment.
Besides the status of the MCG, the second most intersting information for us are the available S3 addresses that we can use to connect to our MCG buckets. We can chose between using the external DNS which incurs DNS traffic cost, or route internally inside of our Openshift cluster.</p>
</div>
<div class="paragraph">
<p>You can get a more basic overview of the MCG status using the Object Storage <strong>Dashboard</strong>. To reach this, log into the <strong>Openshift Web Console</strong>, click on <code>Home</code> and select the <code>Dashboards</code> item. In the main view, select <code>Object Service</code> in the top navigation bar.
This dashboard does not give you connection information for your S3 endpoint, but offers Graphs and runtime information about the usage of your S3 backend.</p>
</div>
</div>
<div class="sect2">
<h3 id="_creating_an_object_bucket_claim">6.2. Creating an Object Bucket Claim</h3>
<div class="paragraph">
<p>An Object Bucket Claim (OBC) can be used to request a S3 compatible bucket backend for your workloads. When creating an OBC you get a ConfigMap (CM) and a Secret that together contain all the information your application needs to use the object storage service.</p>
</div>
<div class="paragraph">
<p>Creating an OBC is as simple as using the NooBaa CLI:</p>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="pygments highlight"><code data-lang="shell"><span></span>noobaa obc create test21obc -n openshift-storage</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Example output:</div>
<div class="content">
<pre class="pygments highlight"><code data-lang="shell"><span></span>INFO<span class="tok-o">[</span><span class="tok-m">0001</span><span class="tok-o">]</span>  Created: ObjectBucketClaim <span class="tok-s2">&quot;test21obc&quot;</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>The NooBaa CLI has created the necessary configuration inside of NooBaa and has informed Openshift about the new OBC:</p>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="pygments highlight"><code data-lang="shell"><span></span>oc get obc -n openshift-storage</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Example output:</div>
<div class="content">
<pre class="pygments highlight"><code data-lang="shell"><span></span>NAME        STORAGE-CLASS                 PHASE   AGE
test21obc   openshift-storage.noobaa.io   Bound   38s</code></pre>
</div>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="pygments highlight"><code data-lang="shell"><span></span>oc get obc test21obc -o yaml -n openshift-storage</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Example output:</div>
<div class="content">
<pre class="pygments highlight"><code data-lang="yaml"><table class="linenotable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23</pre></div></td><td class="code"><pre><span></span><span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">apiVersion</span><span class="tok-p tok-p-Indicator">:</span> <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">objectbucket.io/v1alpha1</span>
<span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">kind</span><span class="tok-p tok-p-Indicator">:</span> <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">ObjectBucketClaim</span>
<span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">metadata</span><span class="tok-p tok-p-Indicator">:</span>
  <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">creationTimestamp</span><span class="tok-p tok-p-Indicator">:</span> <span class="tok-s">&quot;2019-10-24T13:30:07Z&quot;</span>
  <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">finalizers</span><span class="tok-p tok-p-Indicator">:</span>
  <span class="tok-p tok-p-Indicator">-</span> <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">objectbucket.io/finalizer</span>
  <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">generation</span><span class="tok-p tok-p-Indicator">:</span> <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">2</span>
  <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">labels</span><span class="tok-p tok-p-Indicator">:</span>
    <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">app</span><span class="tok-p tok-p-Indicator">:</span> <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">noobaa</span>
    <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">bucket-provisioner</span><span class="tok-p tok-p-Indicator">:</span> <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">openshift-storage.noobaa.io-obc</span>
    <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">noobaa-domain</span><span class="tok-p tok-p-Indicator">:</span> <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">openshift-storage.noobaa.io</span>
  <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">name</span><span class="tok-p tok-p-Indicator">:</span> <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">test21obc</span>
  <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">namespace</span><span class="tok-p tok-p-Indicator">:</span> <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">openshift-storage</span>
  <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">resourceVersion</span><span class="tok-p tok-p-Indicator">:</span> <span class="tok-s">&quot;40756&quot;</span>
  <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">selfLink</span><span class="tok-p tok-p-Indicator">:</span> <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">/apis/objectbucket.io/v1alpha1/namespaces/openshift-storage/objectbucketclaims/test21obc</span>
  <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">uid</span><span class="tok-p tok-p-Indicator">:</span> <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">64f04cba-f662-11e9-bc3c-0295250841af</span>
<span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">spec</span><span class="tok-p tok-p-Indicator">:</span>
  <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">ObjectBucketName</span><span class="tok-p tok-p-Indicator">:</span> <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">obc-openshift-storage-test21obc</span>
  <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">bucketName</span><span class="tok-p tok-p-Indicator">:</span> <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">test21obc-933348a6-e267-4f82-82f1-e59bf4fe3bb4</span>
  <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">generateBucketName</span><span class="tok-p tok-p-Indicator">:</span> <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">test21obc</span>
  <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">storageClassName</span><span class="tok-p tok-p-Indicator">:</span> <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">openshift-storage.noobaa.io</span>
<span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">status</span><span class="tok-p tok-p-Indicator">:</span>
  <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">phase</span><span class="tok-p tok-p-Indicator">:</span> <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">Bound</span>
</pre></td></tr></table></code></pre>
</div>
</div>
<div class="paragraph">
<p>Inside of your <code>openshift-storage</code> namespace, you will now find the <strong>ConfigMap</strong> and the <strong>Secret</strong> to use this OBC. The CM and the secret have the same name as the OBC:</p>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="pygments highlight"><code data-lang="shell"><span></span>oc get -n openshift-storage secret test21obc -o yaml</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Example output:</div>
<div class="content">
<pre class="pygments highlight"><code data-lang="yaml"><span></span><span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">apiVersion</span><span class="tok-p tok-p-Indicator">:</span> <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">v1</span>
<span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">data</span><span class="tok-p tok-p-Indicator">:</span>
  <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">AWS_ACCESS_KEY_ID</span><span class="tok-p tok-p-Indicator">:</span> <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">c0M0R2xVanF3ODR3bHBkVW94cmY=</span>
  <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">AWS_SECRET_ACCESS_KEY</span><span class="tok-p tok-p-Indicator">:</span> <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">Wi9kcFluSWxHRzlWaFlzNk1hc0xma2JXcjM1MVhqa051SlBleXpmOQ==</span>
<span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">kind</span><span class="tok-p tok-p-Indicator">:</span> <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">Secret</span>
<span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">metadata</span><span class="tok-p tok-p-Indicator">:</span>
  <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">creationTimestamp</span><span class="tok-p tok-p-Indicator">:</span> <span class="tok-s">&quot;2019-10-24T13:30:07Z&quot;</span>
  <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">finalizers</span><span class="tok-p tok-p-Indicator">:</span>
  <span class="tok-p tok-p-Indicator">-</span> <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">objectbucket.io/finalizer</span>
  <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">labels</span><span class="tok-p tok-p-Indicator">:</span>
    <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">app</span><span class="tok-p tok-p-Indicator">:</span> <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">noobaa</span>
    <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">bucket-provisioner</span><span class="tok-p tok-p-Indicator">:</span> <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">openshift-storage.noobaa.io-obc</span>
    <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">noobaa-domain</span><span class="tok-p tok-p-Indicator">:</span> <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">openshift-storage.noobaa.io</span>
  <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">name</span><span class="tok-p tok-p-Indicator">:</span> <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">test21obc</span>
  <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">namespace</span><span class="tok-p tok-p-Indicator">:</span> <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">openshift-storage</span>
  <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">ownerReferences</span><span class="tok-p tok-p-Indicator">:</span>
  <span class="tok-p tok-p-Indicator">-</span> <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">apiVersion</span><span class="tok-p tok-p-Indicator">:</span> <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">objectbucket.io/v1alpha1</span>
    <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">blockOwnerDeletion</span><span class="tok-p tok-p-Indicator">:</span> <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">true</span>
    <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">controller</span><span class="tok-p tok-p-Indicator">:</span> <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">true</span>
    <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">kind</span><span class="tok-p tok-p-Indicator">:</span> <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">ObjectBucketClaim</span>
    <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">name</span><span class="tok-p tok-p-Indicator">:</span> <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">test21obc</span>
    <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">uid</span><span class="tok-p tok-p-Indicator">:</span> <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">64f04cba-f662-11e9-bc3c-0295250841af</span>
  <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">resourceVersion</span><span class="tok-p tok-p-Indicator">:</span> <span class="tok-s">&quot;40751&quot;</span>
  <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">selfLink</span><span class="tok-p tok-p-Indicator">:</span> <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">/api/v1/namespaces/openshift-storage/secrets/test21obc</span>
  <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">uid</span><span class="tok-p tok-p-Indicator">:</span> <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">65117c1c-f662-11e9-9094-0a5305de57bb</span>
<span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">type</span><span class="tok-p tok-p-Indicator">:</span> <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">Opaque</span></code></pre>
</div>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="pygments highlight"><code data-lang="shell"><span></span>oc get -n openshift-storage cm test21obc -o yaml</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Example output:</div>
<div class="content">
<pre class="pygments highlight"><code data-lang="yaml"><span></span><span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">apiVersion</span><span class="tok-p tok-p-Indicator">:</span> <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">v1</span>
<span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">data</span><span class="tok-p tok-p-Indicator">:</span>
  <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">BUCKET_HOST</span><span class="tok-p tok-p-Indicator">:</span> <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">10.0.171.35</span>
  <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">BUCKET_NAME</span><span class="tok-p tok-p-Indicator">:</span> <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">test21obc-933348a6-e267-4f82-82f1-e59bf4fe3bb4</span>
  <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">BUCKET_PORT</span><span class="tok-p tok-p-Indicator">:</span> <span class="tok-s">&quot;31242&quot;</span>
  <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">BUCKET_REGION</span><span class="tok-p tok-p-Indicator">:</span> <span class="tok-s">&quot;&quot;</span>
  <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">BUCKET_SUBREGION</span><span class="tok-p tok-p-Indicator">:</span> <span class="tok-s">&quot;&quot;</span>
<span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">kind</span><span class="tok-p tok-p-Indicator">:</span> <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">ConfigMap</span>
<span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">metadata</span><span class="tok-p tok-p-Indicator">:</span>
  <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">creationTimestamp</span><span class="tok-p tok-p-Indicator">:</span> <span class="tok-s">&quot;2019-10-24T13:30:07Z&quot;</span>
  <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">finalizers</span><span class="tok-p tok-p-Indicator">:</span>
  <span class="tok-p tok-p-Indicator">-</span> <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">objectbucket.io/finalizer</span>
  <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">labels</span><span class="tok-p tok-p-Indicator">:</span>
    <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">app</span><span class="tok-p tok-p-Indicator">:</span> <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">noobaa</span>
    <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">bucket-provisioner</span><span class="tok-p tok-p-Indicator">:</span> <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">openshift-storage.noobaa.io-obc</span>
    <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">noobaa-domain</span><span class="tok-p tok-p-Indicator">:</span> <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">openshift-storage.noobaa.io</span>
  <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">name</span><span class="tok-p tok-p-Indicator">:</span> <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">test21obc</span>
  <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">namespace</span><span class="tok-p tok-p-Indicator">:</span> <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">openshift-storage</span>
  <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">ownerReferences</span><span class="tok-p tok-p-Indicator">:</span>
  <span class="tok-p tok-p-Indicator">-</span> <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">apiVersion</span><span class="tok-p tok-p-Indicator">:</span> <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">objectbucket.io/v1alpha1</span>
    <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">blockOwnerDeletion</span><span class="tok-p tok-p-Indicator">:</span> <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">true</span>
    <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">controller</span><span class="tok-p tok-p-Indicator">:</span> <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">true</span>
    <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">kind</span><span class="tok-p tok-p-Indicator">:</span> <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">ObjectBucketClaim</span>
    <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">name</span><span class="tok-p tok-p-Indicator">:</span> <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">test21obc</span>
    <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">uid</span><span class="tok-p tok-p-Indicator">:</span> <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">64f04cba-f662-11e9-bc3c-0295250841af</span>
  <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">resourceVersion</span><span class="tok-p tok-p-Indicator">:</span> <span class="tok-s">&quot;40752&quot;</span>
  <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">selfLink</span><span class="tok-p tok-p-Indicator">:</span> <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">/api/v1/namespaces/openshift-storage/configmaps/test21obc</span>
  <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">uid</span><span class="tok-p tok-p-Indicator">:</span> <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">651c6501-f662-11e9-9094-0a5305de57bb</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>As you can see, the secret gives us the S3 access credentials, while the CM contains the S3 endpoint information for our application.</p>
</div>
</div>
<div class="sect2">
<h3 id="_using_an_obc_inside_a_container">6.3. Using an OBC inside a container</h3>
<div class="paragraph">
<p>In this section we will see how one can create an OBC using a YAML file and use the provided S3 configuration in an example application.</p>
</div>
<div class="paragraph">
<p>To deploy the OBC and the example application we apply this YAML file:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight"><code data-lang="yaml"><span></span><span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">apiVersion</span><span class="tok-p tok-p-Indicator">:</span> <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">objectbucket.io/v1alpha1</span>
<span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">kind</span><span class="tok-p tok-p-Indicator">:</span> <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">ObjectBucketClaim</span>
<span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">metadata</span><span class="tok-p tok-p-Indicator">:</span>
  <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">name</span><span class="tok-p tok-p-Indicator">:</span> <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">obc-test</span>
<span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">spec</span><span class="tok-p tok-p-Indicator">:</span>
  <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">generateBucketName</span><span class="tok-p tok-p-Indicator">:</span> <span class="tok-s">&quot;obc-test-noobaa&quot;</span>
  <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">storageClassName</span><span class="tok-p tok-p-Indicator">:</span> <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">openshift-storage.noobaa.io</span>
<span class="tok-nn">---</span>
<span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">apiVersion</span><span class="tok-p tok-p-Indicator">:</span> <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">batch/v1</span>
<span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">kind</span><span class="tok-p tok-p-Indicator">:</span> <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">Job</span>
<span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">metadata</span><span class="tok-p tok-p-Indicator">:</span>
  <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">name</span><span class="tok-p tok-p-Indicator">:</span> <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">obc-test</span>
  <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">labels</span><span class="tok-p tok-p-Indicator">:</span>
    <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">app</span><span class="tok-p tok-p-Indicator">:</span> <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">obc-test</span>
<span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">spec</span><span class="tok-p tok-p-Indicator">:</span>
  <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">template</span><span class="tok-p tok-p-Indicator">:</span>
    <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">metadata</span><span class="tok-p tok-p-Indicator">:</span>
      <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">labels</span><span class="tok-p tok-p-Indicator">:</span>
        <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">app</span><span class="tok-p tok-p-Indicator">:</span> <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">obc-test</span>
    <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">spec</span><span class="tok-p tok-p-Indicator">:</span>
      <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">restartPolicy</span><span class="tok-p tok-p-Indicator">:</span> <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">OnFailure</span>
      <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">containers</span><span class="tok-p tok-p-Indicator">:</span>
        <span class="tok-p tok-p-Indicator">-</span> <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">image</span><span class="tok-p tok-p-Indicator">:</span> <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">mesosphere/aws-cli:latest</span>
          <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">command</span><span class="tok-p tok-p-Indicator">:</span> <span class="tok-p tok-p-Indicator">[</span><span class="tok-s">&quot;sh&quot;</span><span class="tok-p tok-p-Indicator">]</span>
          <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">args</span><span class="tok-p tok-p-Indicator">:</span>
            <span class="tok-p tok-p-Indicator">-</span> <span class="tok-s">&#39;-c&#39;</span>
            <span class="tok-p tok-p-Indicator">-</span> <span class="tok-s">&#39;set</span><span class="tok-nv"> </span><span class="tok-s">-x</span><span class="tok-nv"> </span><span class="tok-s">&amp;&amp;</span><span class="tok-nv"> </span><span class="tok-s">s3cmd</span><span class="tok-nv"> </span><span class="tok-s">--no-check-certificate</span><span class="tok-nv"> </span><span class="tok-s">--host</span><span class="tok-nv"> </span><span class="tok-s">$BUCKET_HOST:$BUCKET_PORT</span><span class="tok-nv"> </span><span class="tok-s">--host-bucket</span><span class="tok-nv"> </span><span class="tok-s">$BUCKET_HOST:$BUCKET_PORT</span><span class="tok-nv"> </span><span class="tok-s">du&#39;</span>
          <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">name</span><span class="tok-p tok-p-Indicator">:</span> <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">obc-test</span>
          <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">env</span><span class="tok-p tok-p-Indicator">:</span>
            <span class="tok-p tok-p-Indicator">-</span> <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">name</span><span class="tok-p tok-p-Indicator">:</span> <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">BUCKET_NAME</span>
              <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">valueFrom</span><span class="tok-p tok-p-Indicator">:</span>
                <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">configMapKeyRef</span><span class="tok-p tok-p-Indicator">:</span>
                  <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">name</span><span class="tok-p tok-p-Indicator">:</span> <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">obc-test</span>
                  <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">key</span><span class="tok-p tok-p-Indicator">:</span> <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">BUCKET_NAME</span>
            <span class="tok-p tok-p-Indicator">-</span> <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">name</span><span class="tok-p tok-p-Indicator">:</span> <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">BUCKET_HOST</span>
              <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">valueFrom</span><span class="tok-p tok-p-Indicator">:</span>
                <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">configMapKeyRef</span><span class="tok-p tok-p-Indicator">:</span>
                  <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">name</span><span class="tok-p tok-p-Indicator">:</span> <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">obc-test</span>
                  <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">key</span><span class="tok-p tok-p-Indicator">:</span> <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">BUCKET_HOST</span>
            <span class="tok-p tok-p-Indicator">-</span> <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">name</span><span class="tok-p tok-p-Indicator">:</span> <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">BUCKET_PORT</span>
              <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">valueFrom</span><span class="tok-p tok-p-Indicator">:</span>
                <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">configMapKeyRef</span><span class="tok-p tok-p-Indicator">:</span>
                  <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">name</span><span class="tok-p tok-p-Indicator">:</span> <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">obc-test</span>
                  <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">key</span><span class="tok-p tok-p-Indicator">:</span> <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">BUCKET_PORT</span>
            <span class="tok-p tok-p-Indicator">-</span> <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">name</span><span class="tok-p tok-p-Indicator">:</span> <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">AWS_DEFAULT_REGION</span>
              <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">valueFrom</span><span class="tok-p tok-p-Indicator">:</span>
                <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">configMapKeyRef</span><span class="tok-p tok-p-Indicator">:</span>
                  <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">name</span><span class="tok-p tok-p-Indicator">:</span> <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">obc-test</span>
                  <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">key</span><span class="tok-p tok-p-Indicator">:</span> <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">BUCKET_REGION</span>
            <span class="tok-p tok-p-Indicator">-</span> <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">name</span><span class="tok-p tok-p-Indicator">:</span> <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">AWS_ACCESS_KEY_ID</span>
              <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">valueFrom</span><span class="tok-p tok-p-Indicator">:</span>
                <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">secretKeyRef</span><span class="tok-p tok-p-Indicator">:</span>
                  <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">name</span><span class="tok-p tok-p-Indicator">:</span> <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">obc-test</span>
                  <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">key</span><span class="tok-p tok-p-Indicator">:</span> <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">AWS_ACCESS_KEY_ID</span>
            <span class="tok-p tok-p-Indicator">-</span> <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">name</span><span class="tok-p tok-p-Indicator">:</span> <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">AWS_SECRET_ACCESS_KEY</span>
              <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">valueFrom</span><span class="tok-p tok-p-Indicator">:</span>
                <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">secretKeyRef</span><span class="tok-p tok-p-Indicator">:</span>
                  <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">name</span><span class="tok-p tok-p-Indicator">:</span> <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">obc-test</span>
                  <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">key</span><span class="tok-p tok-p-Indicator">:</span> <span class="tok-l tok-l-Scalar tok-l-Scalar-Plain">AWS_SECRET_ACCESS_KEY</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>The first part creates an OBC that will create a ConfigMap and a secret that have the same name as the OBC (<code>obc-test</code>). The second part of the file (after the <code>---</code>), creates a Job that deploys a container with the s3cmd pre-installed. It will execute s3cmd with the appropriate command line arguments and exit. S3cmd will in this case report the current disk usage of our S3 endpoint and exit, which will mark our <strong>Pod</strong> as <code>Completed</code>.</p>
</div>
<div class="paragraph">
<p>Let&#8217;s try this out:</p>
</div>
<div class="listingblock execute">
<div class="title">Deploy the Manifest:</div>
<div class="content">
<pre class="pygments highlight"><code data-lang="shell"><span></span>oc apply <span class="tok-o">{{</span> HOME_PATH <span class="tok-o">}}</span>/support/ocslab_obc-app-example.yaml</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Example output:</div>
<div class="content">
<pre class="pygments highlight"><code data-lang="shell"><span></span>namespace/obc-test created
objectbucketclaim.objectbucket.io/obc-test created
job.batch/obc-test created</code></pre>
</div>
</div>
<div class="paragraph">
<p>Afterwards watch the <strong>Pod</strong> be Created, Run and finally be marked <code>Completed</code> like below - be aware that your Pod name will differ:</p>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="pygments highlight"><code data-lang="shell"><span></span>oc get pods -n obc-test -l <span class="tok-nv">app</span><span class="tok-o">=</span>obc-test</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Example output:</div>
<div class="content">
<pre class="pygments highlight"><code data-lang="shell"><span></span>NAME             READY   STATUS      RESTARTS   AGE
obc-test-bvg8h   <span class="tok-m">0</span>/1     Completed   <span class="tok-m">0</span>          22s</code></pre>
</div>
</div>
<div class="paragraph">
<p>Then you can check the <code>obc-test</code> <strong>Pod</strong> logs for the contents of the S3 bucket using the command below (in this case there are zero objects in the bucket).</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
Fetching the obc-test log via the <code>oc</code> command does not work correctly. It does work using the <code>kubectl</code> command.
</td>
</tr>
</table>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="pygments highlight"><code data-lang="shell"><span></span>kubectl logs -n obc-test -l <span class="tok-nv">app</span><span class="tok-o">=</span>obc-test</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Example output:</div>
<div class="content">
<pre class="pygments highlight"><code data-lang="shell"><span></span>+ s3cmd --no-check-certificate --host <span class="tok-m">10</span>.0.140.19:30052 --host-bucket <span class="tok-m">10</span>.0.140.19:30052 du
<span class="tok-m">0</span>        <span class="tok-m">0</span> objects s3://obc-test-noobaa-784461cb-1e77-4ccf-b62d-007a6ae3ef15/
--------
<span class="tok-m">0</span>        Total</code></pre>
</div>
</div>
<div class="paragraph">
<p>As we can see above, we can access one bucket, which is currently empty. This proves that the access credentials from the OBC work and are set up correctly inside of the container.<br>
Most applications support reading out the <code>AWS_ACCESS_KEY_ID</code> and <code>AWS_SECRET_ACCESS_KEY</code> environment variables natively, but you will have to figure out how to set the host and bucket name for each application. In our example we used CLI flags of s3cmd for this.</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_adding_storage_to_the_ceph_cluster">7. Adding storage to the Ceph Cluster</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Adding storage to OCS adds capacity and performance to your already present cluster.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph">
<p>The reason for adding more OCP worker nodes for storage is because the existing nodes do not have adequate CPU and/or Memory available.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="sect2">
<h3 id="_add_storage_worker_nodes">7.1. Add storage worker nodes</h3>
<div class="paragraph">
<p>This section will explain how one can add more worker nodes to the present storage cluster. Afterwards follow the next sub-section on how to extend the OCS cluster to provision storage on these new nodes.</p>
</div>
<div class="paragraph">
<p>To add more nodes, we could either add more machinesets like we did before, or scale the already present OCS machinesets. For this training, we will spawn more workers by scaling the already present OCS worker instances up:</p>
</div>
<div class="listingblock execute">
<div class="title">Check on our present machinesets:</div>
<div class="content">
<pre class="pygments highlight"><code data-lang="shell"><span></span>oc get machinesets -n openshift-machine-api <span class="tok-p">|</span> egrep <span class="tok-s1">&#39;NAME|workerocs&#39;</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>Example output:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight"><code data-lang="shell"><span></span>NAME                                          DESIRED   CURRENT   READY   AVAILABLE   AGE
cluster-ocs-0ec4-dgwqc-workerocs-us-east-2a   <span class="tok-m">1</span>         <span class="tok-m">1</span>         <span class="tok-m">1</span>       <span class="tok-m">1</span>           3h50m
cluster-ocs-0ec4-dgwqc-workerocs-us-east-2b   <span class="tok-m">1</span>         <span class="tok-m">1</span>         <span class="tok-m">1</span>       <span class="tok-m">1</span>           3h50m
cluster-ocs-0ec4-dgwqc-workerocs-us-east-2c   <span class="tok-m">1</span>         <span class="tok-m">1</span>         <span class="tok-m">1</span>       <span class="tok-m">1</span>           3h50m</code></pre>
</div>
</div>
<div class="paragraph">
<p>Let&#8217;s scale the workerocs machinesets up with this command:</p>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="pygments highlight"><code data-lang="shell"><span></span>oc get machinesets -n openshift-machine-api -o name <span class="tok-p">|</span> grep workerocs <span class="tok-p">|</span> xargs -n1 -t oc scale -n openshift-machine-api --replicas<span class="tok-o">=</span><span class="tok-m">2</span></code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Example output:</div>
<div class="content">
<pre class="pygments highlight"><code data-lang="shell"><span></span>oc scale -n openshift-machine-api --replicas<span class="tok-o">=</span><span class="tok-m">2</span> machineset.machine.openshift.io/cluster-ocs-0ec4-dgwqc-workerocs-us-east-2a
machineset.machine.openshift.io/cluster-ocs-0ec4-dgwqc-workerocs-us-east-2a scaled
oc scale -n openshift-machine-api --replicas<span class="tok-o">=</span><span class="tok-m">2</span> machineset.machine.openshift.io/cluster-ocs-0ec4-dgwqc-workerocs-us-east-2b
machineset.machine.openshift.io/cluster-ocs-0ec4-dgwqc-workerocs-us-east-2b scaled
oc scale -n openshift-machine-api --replicas<span class="tok-o">=</span><span class="tok-m">2</span> machineset.machine.openshift.io/cluster-ocs-0ec4-dgwqc-workerocs-us-east-2c
machineset.machine.openshift.io/cluster-ocs-0ec4-dgwqc-workerocs-us-east-2c scaled</code></pre>
</div>
</div>
<div class="paragraph">
<p>Wait until the new workers are available. This could take 5 minutes or more so be patient.</p>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="pygments highlight"><code data-lang="shell"><span></span>watch <span class="tok-s2">&quot;oc get machinesets -n openshift-machine-api | egrep &#39;NAME|workerocs&#39;&quot;</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>You can exit by pressing <span class="keyseq"><kbd>Ctrl</kbd>+<kbd>C</kbd></span>.</p>
</div>
<div class="paragraph">
<p>Once they are available, we can check on which worker nodes do not have OCS label applied yet, these are the new workers just created.</p>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="pygments highlight"><code data-lang="shell"><span></span>oc get node --show-labels <span class="tok-p">|</span> grep storage-node <span class="tok-p">|</span> grep -v openshift-storage <span class="tok-p">|</span> cut -d<span class="tok-s1">&#39; &#39;</span> -f1</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Example output:</div>
<div class="content">
<pre class="pygments highlight"><code data-lang="shell"><span></span>ip-10-0-133-99.us-east-2.compute.internal
ip-10-0-158-153.us-east-2.compute.internal
ip-10-0-160-200.us-east-2.compute.internal</code></pre>
</div>
</div>
<div class="paragraph">
<p>We can see that there are three new nodes, which do not yet have the <code>cluster.ocs.openshift.io/openshift-storage</code> label applied yet. We will apply this now:</p>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="pygments highlight"><code data-lang="shell"><span></span>oc get nodes -o json <span class="tok-p">|</span> jq <span class="tok-s1">&#39;.items[] | select(.metadata.labels.role == &quot;storage-node&quot;) | .metadata.name&#39;</span> <span class="tok-p">|</span> xargs -n1 -t -I <span class="tok-o">{}</span> oc label nodes <span class="tok-o">{}</span> cluster.ocs.openshift.io/openshift-storage<span class="tok-o">=</span><span class="tok-s2">&quot;&quot;</span></code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Example output:</div>
<div class="content">
<pre class="pygments highlight"><code data-lang="shell"><span></span>oc label nodes ip-10-0-131-209.us-east-2.compute.internal cluster.ocs.openshift.io/openshift-storage<span class="tok-o">=</span>
error: <span class="tok-s1">&#39;cluster.ocs.openshift.io/openshift-storage&#39;</span> already has a value <span class="tok-o">()</span>, and --overwrite is <span class="tok-nb">false</span>
oc label nodes ip-10-0-133-99.us-east-2.compute.internal cluster.ocs.openshift.io/openshift-storage<span class="tok-o">=</span>
node/ip-10-0-133-99.us-east-2.compute.internal labeled
oc label nodes ip-10-0-155-12.us-east-2.compute.internal cluster.ocs.openshift.io/openshift-storage<span class="tok-o">=</span>
error: <span class="tok-s1">&#39;cluster.ocs.openshift.io/openshift-storage&#39;</span> already has a value <span class="tok-o">()</span>, and --overwrite is <span class="tok-nb">false</span>
oc label nodes ip-10-0-158-153.us-east-2.compute.internal cluster.ocs.openshift.io/openshift-storage<span class="tok-o">=</span>
node/ip-10-0-158-153.us-east-2.compute.internal labeled
oc label nodes ip-10-0-160-200.us-east-2.compute.internal cluster.ocs.openshift.io/openshift-storage<span class="tok-o">=</span>
node/ip-10-0-160-200.us-east-2.compute.internal labeled
oc label nodes ip-10-0-162-215.us-east-2.compute.internal cluster.ocs.openshift.io/openshift-storage<span class="tok-o">=</span>
error: <span class="tok-s1">&#39;cluster.ocs.openshift.io/openshift-storage&#39;</span> already has a value <span class="tok-o">()</span>, and --overwrite is <span class="tok-nb">false</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>You will see errors for the nodes which already had the OCS label applied, which is fine.<br>
Now that you have the new instances prepared for extending the cluster by adding the OCS label, the next step is to add more storage to the Ceph cluster. The OCS operator will prefer the new OCP nodes because they have no OCS resources scheduled yet.</p>
</div>
</div>
<div class="sect2">
<h3 id="_add_storage_capacity">7.2. Add storage capacity</h3>
<div class="paragraph">
<p>In this section we will add storage capacity and performance to the configured OCS worker nodes and the Ceph cluster. If you have followed the previous section you should now have 6 OCS nodes.</p>
</div>
<div class="paragraph">
<p>To add storage, go to the <strong>Openshift Web Console</strong> and follow these steps to reach the OCS storage cluster overview:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Click on <code>Operators</code> on the left navigation bar</p>
</li>
<li>
<p>Select <code>Installed Operators</code> and select <code>openshift-storage</code> project</p>
</li>
<li>
<p>Click on <code>Openshift Container Storage Operator</code></p>
</li>
<li>
<p>In the top navigation bar, scroll right to find the item <code>Storage Cluster</code> and click on it</p>
</li>
</ul>
</div>
<div class="imageblock">
<div class="content">
<img src="images/ocs/OCS-Storage-Cluster-overview-reachit.png" alt="OCS Storage Cluster overview reachit">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>The visible list should list only one item - click on the three dots on the far right to extend the options menu</p>
</li>
<li>
<p>Select <code>Add Capacity</code> from the options menu</p>
</li>
</ul>
</div>
<div class="imageblock">
<div class="content">
<img src="images/ocs/OCS-add-capacity.png" alt="OCS add capacity">
</div>
<div class="title">Figure 14. Add capacity dialog</div>
</div>
<div class="paragraph">
<p>In the new dialog you can set the requested additional (usable) capacity and the storage class. On AWS, the storage class should be set to <code>gp2</code>.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
The effectively provisioned capacity will be three times as much as you put into the <code>Requested Capacity</code> field, because OCS uses a replica count of 3.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Once you are done with your setting, proceed by clicking on <code>Add</code>. You will see the Status of the Storage Cluster change until it reaches <code>Ready</code> again.</p>
</div>
<div class="paragraph">
<p>You can now see that there are new OSD pods:</p>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="pygments highlight"><code data-lang="shell"><span></span>oc get pod -o<span class="tok-o">=</span>custom-columns<span class="tok-o">=</span>NAME:.metadata.name,STATUS:.status.phase,NODE:.spec.nodeName -n openshift-storage <span class="tok-p">|</span> grep osd</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Example output:</div>
<div class="content">
<pre class="pygments highlight"><code data-lang="shell"><span></span>NAME                                                              STATUS      NODE
rook-ceph-osd-0-8675cf4f4-7gpbv                                   Running     ip-10-0-155-12.us-east-2.compute.internal
rook-ceph-osd-1-58b9d954cf-9s6bw                                  Running     ip-10-0-162-215.us-east-2.compute.internal
rook-ceph-osd-2-6994dd5f44-hsqrv                                  Running     ip-10-0-131-209.us-east-2.compute.internal
rook-ceph-osd-3-6675d5495c-7p68z                                  Running     ip-10-0-133-99.us-east-2.compute.internal
rook-ceph-osd-4-8665bfc79b-xn8xg                                  Running     ip-10-0-160-200.us-east-2.compute.internal
rook-ceph-osd-5-8ffff58d6-kscbt                                   Running     ip-10-0-158-153.us-east-2.compute.internal
rook-ceph-osd-prepare-ocs-deviceset-0-0-d2ppm-vvlt8               Succeeded   ip-10-0-131-209.us-east-2.compute.internal
rook-ceph-osd-prepare-ocs-deviceset-0-1-869tk-btn8x               Succeeded   ip-10-0-133-99.us-east-2.compute.internal
rook-ceph-osd-prepare-ocs-deviceset-1-0-9tmc6-svb84               Succeeded   ip-10-0-162-215.us-east-2.compute.internal
rook-ceph-osd-prepare-ocs-deviceset-1-1-7qsxd-lppp6               Succeeded   ip-10-0-160-200.us-east-2.compute.internal
rook-ceph-osd-prepare-ocs-deviceset-2-0-qtbfv-j4nr4               Succeeded   ip-10-0-155-12.us-east-2.compute.internal
rook-ceph-osd-prepare-ocs-deviceset-2-1-glsgj-x4k7t               Succeeded   ip-10-0-158-153.us-east-2.compute.internal</code></pre>
</div>
</div>
<div class="paragraph">
<p>This is everything that you need to do to extend the OCS storage.</p>
</div>
</div>
<div class="sect2">
<h3 id="_verify_new_storage">7.3. Verify new storage</h3>
<div class="paragraph">
<p>Once you added the capacity and made sure that the OSD pods are present, you can also optionally check the additional storage capacity using the Ceph tools. To do this, follow these steps:</p>
</div>
<div class="listingblock execute">
<div class="title">Enter the tools pod that you created in <a href="#_using_the_rook_ceph_toolbox_to_check_on_the_ceph_backing_storage">the previous section</a>:</div>
<div class="content">
<pre class="pygments highlight"><code data-lang="shell"><span></span><span class="tok-nv">TOOLS_POD</span><span class="tok-o">=</span><span class="tok-k">$(</span>oc get pods -n openshift-storage -l <span class="tok-nv">app</span><span class="tok-o">=</span>rook-ceph-tools -o name<span class="tok-k">)</span>
oc rsh -n openshift-storage <span class="tok-nv">$TOOLS_POD</span></code></pre>
</div>
</div>
<div class="listingblock execute">
<div class="title">Check the status of the Ceph cluster:</div>
<div class="content">
<pre class="pygments highlight"><code data-lang="shell"><span></span>ceph status</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Example output:</div>
<div class="content">
<pre class="pygments highlight"><code data-lang="shell"><span></span>sh-4.2# ceph status
  cluster:
    id:     786dbab2-ae4f-4352-8d83-5e27c6a4f341
    health: HEALTH_OK

  services:
    mon: <span class="tok-m">3</span> daemons, quorum a,b,c <span class="tok-o">(</span>age 6h<span class="tok-o">)</span>
    mgr: a<span class="tok-o">(</span>active, since 6h<span class="tok-o">)</span>
    mds: ocs-storagecluster-cephfilesystem:1 <span class="tok-o">{</span><span class="tok-nv">0</span><span class="tok-o">=</span>ocs-storagecluster-cephfilesystem-a<span class="tok-o">=</span>up:active<span class="tok-o">}</span> <span class="tok-m">1</span> up:standby-replay
    osd: <span class="tok-m">6</span> osds: <span class="tok-m">6</span> up <span class="tok-o">(</span>since 6m<span class="tok-o">)</span>, <span class="tok-m">6</span> in <span class="tok-o">(</span>since 6m<span class="tok-o">)</span> <i class="conum" data-value="1"></i><b>(1)</b>

  data:
    pools:   <span class="tok-m">3</span> pools, <span class="tok-m">24</span> pgs
    objects: <span class="tok-m">182</span> objects, <span class="tok-m">311</span> MiB
    usage:   <span class="tok-m">6</span>.7 GiB used, <span class="tok-m">6</span>.0 TiB / <span class="tok-m">6</span>.0 TiB avail <i class="conum" data-value="2"></i><b>(2)</b>
    pgs:     <span class="tok-m">24</span> active+clean

  io:
    client:   <span class="tok-m">853</span> B/s rd, <span class="tok-m">43</span> KiB/s wr, <span class="tok-m">1</span> op/s rd, <span class="tok-m">3</span> op/s wr</code></pre>
</div>
</div>
<div class="paragraph">
<p>In the Ceph status output, we can already see that:</p>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>We now use 6 osds in total and they are <code>up</code> and <code>in</code> (meaning the daemons are running and being used to store data)</td>
</tr>
<tr>
<td><i class="conum" data-value="2"></i><b>2</b></td>
<td>The available raw capacity has increased from 3 TiB to 6 TiB</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Besides that, nothing has changed in the output.</p>
</div>
<div class="listingblock execute">
<div class="title">Check the topology of your cluster:</div>
<div class="content">
<pre class="pygments highlight"><code data-lang="shell"><span></span>ceph osd crush tree</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Example output:</div>
<div class="content">
<pre class="pygments highlight"><code data-lang="shell"><span></span>ID  CLASS WEIGHT  TYPE NAME
 -1       <span class="tok-m">5</span>.99396 root default
 -5       <span class="tok-m">5</span>.99396     region us-east-1
 -4       <span class="tok-m">1</span>.99799         zone us-east-1a
 -3       <span class="tok-m">0</span>.99899             host ocs-deviceset-2-0-cx2vg
  <span class="tok-m">0</span>   ssd <span class="tok-m">0</span>.99899                 osd.0
-19       <span class="tok-m">0</span>.99899             host ocs-deviceset-2-1-4j7fb <i class="conum" data-value="1"></i><b>(1)</b>
  <span class="tok-m">5</span>   ssd <span class="tok-m">0</span>.99899                 osd.5
-10       <span class="tok-m">1</span>.99799         zone us-east-1b
 -9       <span class="tok-m">0</span>.99899             host ocs-deviceset-1-0-s87kw
  <span class="tok-m">1</span>   ssd <span class="tok-m">0</span>.99899                 osd.1
-21       <span class="tok-m">0</span>.99899             host ocs-deviceset-1-1-2rjn6 <i class="conum" data-value="1"></i><b>(1)</b>
  <span class="tok-m">4</span>   ssd <span class="tok-m">0</span>.99899                 osd.4
-14       <span class="tok-m">1</span>.99799         zone us-east-1c
-13       <span class="tok-m">0</span>.99899             host ocs-deviceset-0-0-chvdn
  <span class="tok-m">2</span>   ssd <span class="tok-m">0</span>.99899                 osd.2
-17       <span class="tok-m">0</span>.99899             host ocs-deviceset-0-1-pt9ts <i class="conum" data-value="1"></i><b>(1)</b>
  <span class="tok-m">3</span>   ssd <span class="tok-m">0</span>.99899                 osd.3</code></pre>
</div>
</div>
<div class="colist arabic">
<table>
<tr>
<td><i class="conum" data-value="1"></i><b>1</b></td>
<td>We now have additional hosts, which are extending the hosts in the respective zone</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Since our Ceph cluster&#8217;s CRUSH rules are set up to replicate data between the zones, this is an effective way to relax the load on the previous nodes.</p>
</div>
<div class="paragraph">
<p>Existing data on the original OSDs will be balanced out automatically, so that the old and the new OSDs share the load.</p>
</div>
<div class="paragraph">
<p>Disconnect from the Ceph toolbox pod.</p>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="pygments highlight"><code data-lang="shell"><span></span><span class="tok-nb">exit</span></code></pre>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_monitoring_the_ocs_environment">8. Monitoring the OCS environment</h2>
<div class="sectionbody">
<div class="paragraph">
<p>This section covers the different tools available with OCS 4.2 when it comes to monitoring the environment. This section relies on the existing UI.</p>
</div>
<div class="paragraph">
<p>Individuals already familiar with OCP will feel comfortable with this section but for those who are not, it will be a good bootstrap.</p>
</div>
<div class="paragraph">
<p>The tools are accessible through the main UI window left pane. Click the <strong>Monitoring</strong> menu item to expand and have access to the following 3 choices:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Alerting</p>
</li>
<li>
<p>Metrics</p>
</li>
<li>
<p>Dashboards</p>
</li>
</ul>
</div>
<div class="sect2">
<h3 id="_alerting">8.1. Alerting</h3>
<div class="paragraph">
<p>Click on the <strong>Alerting</strong> item to open the Alert window as illustrated in the screen capture below.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/ocs/metrics-alertingleftpanemenu.png" alt="OCP Monitoring Menu">
</div>
<div class="title">Figure 15. OCP Monitoring Menu</div>
</div>
<div class="paragraph">
<p>This will take you to the <strong>Alerting</strong> homepage as illustrated below.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/ocs/metrics-alertinghomepage.png" alt="OCP Alerting Homepage">
</div>
<div class="title">Figure 16. OCP Alerting Homepage</div>
</div>
<div class="paragraph">
<p>You can display the alerts in the main window by state. To do so you must highlight the states you want to display. The states are:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>Firing</code> - Alert has been confirmed</p>
</li>
<li>
<p><code>Silenced</code> - Alerts that have been silenced while they were in <code>Pending</code> or <code>Firing</code> state</p>
</li>
<li>
<p><code>Pending</code> - Alerts that have been triggered but not confirmed</p>
</li>
<li>
<p><code>Not Firing</code> - Alerts that have not been triggered</p>
</li>
</ul>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
An alert transitions from <code>Pending</code> to <code>Firing</code> state if it persists for more than the amount of time configured in the alert definition (e.g. 10 minutes for the <code>CephClusterWarningState</code> alert).
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>As illustrated below, you can filter the alerts being displayed based on their state. Just click on the states to display to toggle the filter. The states highlighted in blue will be displayed.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
You need at least one state highlighted.
</td>
</tr>
</table>
</div>
<div class="imageblock">
<div class="content">
<img src="images/ocs/metrics-alertingstatusfilter.png" alt="OCP Alert Status Filtering">
</div>
<div class="title">Figure 17. OCP Alerting Status Filtering</div>
</div>
<div class="paragraph">
<p>As illustrated below, you can also filter alerts by name using the <strong>Filter</strong> area on the top right of the window to search for a particular alert or set of alerts.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/ocs/metrics-alertingnamefilter.png" alt="OCP Alert Name Filtering">
</div>
<div class="title">Figure 18. OCP Alerting Name Filtering</div>
</div>
<div class="paragraph">
<p>Through the 3 dot icon on the right hand side of each alert line you have access to a contextual menu to either view the alert definition or to silence the alert.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/ocs/metrics-alertingcontextualmenu.png" alt="OCP Alert Contextual Menu">
</div>
<div class="title">Figure 19. OCP Alert Contextual Menu</div>
</div>
<div class="paragraph">
<p>If you select <code>View Alerting Rule</code> you will get access to the details of the rule that triggered the alert. The details include the Prometheus query used by the alert to perform the detection of the condition.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/ocs/metrics-alertingviewrule.png" alt="OCP Alert Detailed Display">
</div>
<div class="title">Figure 20. OCP Alert Detail Display</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
If desired, you can click the Prometheus query embedded in the alert. Doing so will take you to the <strong>Metrics</strong> page where you will be able to execute the alert and to test updates to the alert.
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="_metrics">8.2. Metrics</h3>
<div class="paragraph">
<p>Click on the <strong>Metrics</strong> item as illustrated below.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/ocs/metrics-metricsleftpanemenu.png" alt="OCP Metrics Menu">
</div>
<div class="title">Figure 21. OCP Metrics Menu</div>
</div>
<div class="paragraph">
<p>This will take you to the <strong>Metrics</strong> homepage as illustrated below.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/ocs/metrics-queryfield.png" alt="OCP Monitoring Metrics Homepage">
</div>
<div class="title">Figure 22. OCP UI Metrics Homepage</div>
</div>
<div class="paragraph">
<p>Use the query field to either enter the formula of your choice or to search for metrics by name. The metrics available will let you query both OCP related information or OCS related information. The queries can be simple or complex using the Prometheus query syntax and all its available functions.</p>
</div>
<div class="paragraph">
<p>Let&#8217;s start testing a simple query example and enter the following text <code>ceph_osd_op</code> in the query field. When you are done typing, simply hit <kbd>Enter</kbd></p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/ocs/metrics-simplecephquery.png" alt="Ceph Simple Query">
</div>
<div class="title">Figure 23. Simple Ceph Query</div>
</div>
<div class="paragraph">
<p>The window should refresh with a graph similar to the one below.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/ocs/metrics-simplecephgraph.png" alt="Ceph Simple Graph">
</div>
<div class="title">Figure 24. Simple Ceph Graph</div>
</div>
<div class="paragraph">
<p>Then let&#8217;s try a more relevant query example and enter the following text <code>rate(ceph_osd_op[5m])</code> or <code>irate(ceph_osd_op[5m])</code> in the query field. When you are done typing, simply hit <kbd>Enter</kbd></p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/ocs/metrics-complexcephquery.png" alt="Ceph Complex Query">
</div>
<div class="title">Figure 25. Complex Ceph Query</div>
</div>
<div class="paragraph">
<p>The window should refresh with a graph similar to the one below.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/ocs/metrics-complexcephgraph.png" alt="Ceph Complex Graph">
</div>
<div class="title">Figure 26. Complex Ceph Graph</div>
</div>
<div class="paragraph">
<p>All OCP metrics are also available through the integrated <strong>Metrics</strong> window. Feel free to try with any of the OCP related metrics such as <code>process_cpu_seconds_total</code> for example.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/ocs/metrics-complexocpgraph.png" alt="OCP Complex Graph">
</div>
<div class="title">Figure 27. Complex OCP Graph</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
Have a look at the difference between <code>sum(irate(process_cpu_seconds_total[5m]))</code> and <code>irate(process_cpu_seconds_total[5m])</code> for instance.
</td>
</tr>
</table>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph">
<p>For more information on the Prometheus query language visit the <a href="https://prometheus.io/docs/prometheus/latest/querying/basics/">Prometheus Query Documentation</a>.</p>
</div>
</td>
</tr>
</table>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_using_must_gather">9. Using must-gather</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Must-gather is a tool for collecting data about the current&#8217;y running Openshift cluster. It loads a predefined set of containers that execute multiple programs and dump it on the local workstations filesystem.
The local files can then be used by a remote support engineer to debug a problem more easily without needing direct cluster access. This is similar to sosreports for RHEL hosts.</p>
</div>
<div class="paragraph">
<p>The OCS team has released its own image for the must-gather tool that runs storage specific commands.</p>
</div>
<div class="paragraph">
<p>You can run this diagnostic tool like this for generic Openshift debugging:</p>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="pygments highlight"><code data-lang="shell"><span></span>oc adm must-gather</code></pre>
</div>
</div>
<div class="paragraph">
<p>Or like this for OCS specific insights:</p>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="pygments highlight"><code data-lang="shell"><span></span>oc adm must-gather --image<span class="tok-o">=</span>quay.io/rhceph-dev/ocs-must-gather</code></pre>
</div>
</div>
<div class="paragraph">
<p>The output will then be saved in the current directory inside of a new folder called <code>must-gather.local.(random)</code></p>
</div>
<div class="paragraph">
<p>More runtime options can be displayed with this command:</p>
</div>
<div class="listingblock execute">
<div class="content">
<pre class="pygments highlight"><code data-lang="shell"><span></span>oc adm must-gather -h</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Example output:</div>
<div class="content">
<pre class="pygments highlight"><code data-lang="shell"><span></span>Launch a pod to gather debugging information

 This <span class="tok-nb">command</span> will launch a pod in a temporary namespace on your cluster that gathers debugging information and <span class="tok-k">then</span>
downloads the gathered information.

 Experimental: This <span class="tok-nb">command</span> is under active development and may change without notice.

Usage:
  oc adm must-gather <span class="tok-o">[</span>flags<span class="tok-o">]</span>

Examples:
  <span class="tok-c1"># gather information using the default plug-in image and command, writing into ./must-gather.local.&lt;rand&gt;</span>
  oc adm must-gather

  <span class="tok-c1"># gather information with a specific local folder to copy to</span>
  oc adm must-gather --dest-dir<span class="tok-o">=</span>/local/directory

  <span class="tok-c1"># gather information using multiple plug-in images</span>
  oc adm must-gather --image<span class="tok-o">=</span>quay.io/kubevirt/must-gather --image<span class="tok-o">=</span>quay.io/openshift/origin-must-gather

  <span class="tok-c1"># gather information using a specific image stream plug-in</span>
  oc adm must-gather --image-stream<span class="tok-o">=</span>openshift/must-gather:latest

  <span class="tok-c1"># gather information using a specific image, command, and pod-dir</span>
  oc adm must-gather --image<span class="tok-o">=</span>my/image:tag --source-dir<span class="tok-o">=</span>/pod/directory -- myspecial-command.sh

Options:
      --dest-dir<span class="tok-o">=</span><span class="tok-s1">&#39;&#39;</span>: Set a specific directory on the <span class="tok-nb">local</span> machine to write gathered data to.
      --image<span class="tok-o">=[]</span>: Specify a must-gather plugin image to run. If not specified, OpenShift<span class="tok-s1">&#39;s default must-gather image</span>
<span class="tok-s1">will be used.</span>
<span class="tok-s1">      --image-stream=[]: Specify an image stream (namespace/name:tag) containing a must-gather plugin image to run.</span>
<span class="tok-s1">      --node-name=&#39;&#39;: Set a specific node to use - by default a random master will be used</span>
<span class="tok-s1">      --source-dir=&#39;</span>/must-gather/<span class="tok-err">&#39;</span>: Set the specific directory on the pod copy the gathered data from.

Use <span class="tok-s2">&quot;oc adm options&quot;</span> <span class="tok-k">for</span> a list of global command-line options <span class="tok-o">(</span>applies to all commands<span class="tok-o">)</span>.</code></pre>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_introduction_to_ceph">Appendix A: Introduction to Ceph</h2>
<div class="sectionbody">
<div class="paragraph">
<p>This section will go through Ceph fundamental knowledge for a better understanding of the underlying storage solution
used by OCS 4.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph">
<p>The content in this Appendix is relevant to learning about the critical components of Ceph and how Ceph works. OCS 4 uses Ceph in a prescribed manner for providing storage to OpenShift applications. Using <strong>Operators</strong> and <strong>CustomResourceDefinitions</strong> (CRDs) for deploying and managing OCS 4 may restrict some of Ceph&#8217;s advanced features when compared to general use outside of OCP 4.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph lead">
<p><strong>Timeline</strong></p>
</div>
<div class="paragraph">
<p>The Ceph project has a long history as you can see in the timeline below.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/ocs/ceph101-timeline.png" alt="Ceph Project Timeline">
</div>
<div class="title">Figure 28. Ceph Project History</div>
</div>
<div class="paragraph lead">
<p>It is a battle-tested software defined storage (SDS) solution that has been available as a storage backend for OpenStack and Kubernetes for quite some time.</p>
</div>
<div class="paragraph lead">
<p><strong>Architecture</strong></p>
</div>
<div class="paragraph">
<p>The Ceph cluster provides a scalable storage solution while providing multiple access methods to enable the different types of
clients present within the IT infrastructure to get access to the data.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/ocs/ceph101-overview.png" alt="Ceph From Above">
</div>
<div class="title">Figure 29. Ceph Architecture</div>
</div>
<div class="paragraph lead">
<p>The entire Ceph architecture is resilient and does not present any single point of failure (SPOF).</p>
</div>
<div class="paragraph lead">
<p><strong>RADOS</strong></p>
</div>
<div class="paragraph">
<p>The heart of Ceph is an object store known as RADOS (Reliable Autonomic Distributed Object Store) bottom layer on the screen. This
layer provides the Ceph software defined storage with the ability to store data (serve IO requests, to protect the data, to check
the consistency and the integrity of the data through built-in mechanisms. The RADOS layer is composed of the following daemons:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>MONs or Monitors</p>
</li>
<li>
<p>OSDs or Object Storage Devices</p>
</li>
<li>
<p>MGRs or Managers</p>
</li>
<li>
<p>MDSs or Meta Data Servers</p>
</li>
</ol>
</div>
<div class="paragraph">
<div class="title"><strong><em>Monitors</em></strong></div>
<p>The Monitors maintain the cluster map and state and provide distributed decision-making while configured in an odd number, 3 or 5 depending
on the size and the topology of the cluster, to prevent split-brain situations. The Monitors are not in the data-path and do not serve IO
requests to and from the clients.</p>
</div>
<div class="paragraph">
<div class="title"><strong><em>OSDs</em></strong></div>
<p>One OSD is typically deployed for each local block devices and the native scalable nature of Ceph allows for thousands of OSDs to be part of the cluster.
The OSDs are serving IO requests from the clients while guaranteeing the protection of the data (replication or erasure coding), the rebalancing of the data
in case of an OSD or a node failure, the coherence of the data (scrubbing and deep-scrubbing of the existing data).</p>
</div>
<div class="paragraph">
<div class="title"><strong><em>MGRs</em></strong></div>
<p>The Managers are tightly integrated with the Monitors and collect the statistics within the cluster. Additionally they provide an extensible framework for the
cluster through a pluggable Python interface aimed at expanding the Ceph existing capabilities. The current list of modules developed around the Manager framework
are:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Balancer module</p>
</li>
<li>
<p>Placement Group auto-scaler module</p>
</li>
<li>
<p>Dashboard module</p>
</li>
<li>
<p>RESTful module</p>
</li>
<li>
<p>Prometheus module</p>
</li>
<li>
<p>Zabbix module</p>
</li>
<li>
<p>Rook module</p>
</li>
</ul>
</div>
<div class="paragraph">
<div class="title"><strong><em>MDSs</em></strong></div>
<p>The Meta Data Servers manage the metadata for the POSIX compliant shared filesystem such as the directory hierarchy and the file metadata (ownership, timestamps, mode, &#8230;&#8203;).
All the metadata is stored with RADOS and they do not server any data to the clients. MDSs are only deployed when a shared filesystem is configured in the Ceph cluster.</p>
</div>
<div class="paragraph">
<p>If we look at the Ceph cluster foundation layer, the full picture with the different types of daemons or containers looks like this.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/ocs/ceph101-rados.png" alt="RADOS Overview">
</div>
<div class="title">Figure 30. RADOS as it stands</div>
</div>
<div class="paragraph">
<p>The circle represent the MONs, the 'M' represent the MGRs and the squares with the bars represent the OSDs. In the diagram above, the cluster operates with
3 Monitors, 2 Managers and 23 OSDs.</p>
</div>
<div class="paragraph lead">
<p><strong>Access Methods</strong></p>
</div>
<div class="paragraph">
<p>Ceph was designed to provides the IT environment with all the necessary access methods so that any application can use what is the best solution for its use-case.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/ocs/ceph101-differentstoragetypes.png" alt="Ceph Access Modes">
</div>
<div class="title">Figure 31. Different Storage Types Supported</div>
</div>
<div class="paragraph">
<p>Ceph supports block storage through the RADOS Block Device (aka RBD) access method, file storage through the Ceph Filesystem (aka CephFS) access method and
object storage through its native <code>librados</code> API or through the RADOS Gateway (aka RADOSGW or RGW) for compatibility with the S3 and Swift protocols.</p>
</div>
<div class="paragraph lead">
<p><strong>Librados</strong></p>
</div>
<div class="paragraph">
<p>Librados allows developers to code natively against the native Ceph cluster API for maximum efficiency combined with a small footprint.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/ocs/ceph101-librados.png" alt="librados">
</div>
<div class="title">Figure 32. Application Native Object API</div>
</div>
<div class="paragraph">
<p>The Ceph native API offers different wrappers such as C, C++, Python, Java, Ruby, Erlang, Go and Rust.</p>
</div>
<div class="paragraph lead">
<p><strong>RADOS Block Device (RBD)</strong></p>
</div>
<div class="paragraph">
<p>This access method is used in Red Hat Enterprise Linux or OpenShift version 3.x or 4.x. RBDs can be accessed either through a kernel module (RHEL, OCS4)
or through the <code>librbd</code> API (RHOSP). In the OCP world, RBDs are designed to address the need for RWO PVCs.</p>
</div>
<div class="paragraph lead">
<p><strong><em>Kernel Module (kRBD)</em></strong></p>
</div>
<div class="paragraph">
<p>The kernel RBD driver offers superior performance compared to the userspace <code>librbd</code> method. However, kRBD is currently limited and does
not provide the same level of functionality. e.g., no RBD Mirroring support.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/ocs/ceph101-krbd.png" alt="Kernel based RADOS Block Device">
</div>
<div class="title">Figure 33. kRBD Diagram</div>
</div>
<div class="paragraph lead">
<p><strong><em>Userspace RBD (librbd)</em></strong></p>
</div>
<div class="paragraph">
<p>This access method is used in Red Hat OpenStack Environment or OpenShift through the RBD-NBD driver when available starting in the RHEL 8.1 kernel.
This mode allows us to leverage all existing RBD features such as RBD Mirroring.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/ocs/ceph101-librbd.png" alt="Userspace RADOS Block Device">
</div>
<div class="title">Figure 34. librbd Diagram</div>
</div>
<div class="paragraph lead">
<p><strong><em>Shared Filesystem (CephFS)</em></strong></p>
</div>
<div class="paragraph">
<p>This method allows clients to jointly access a shared POSIX compliant filesystem. The client initially contacts the Meta Data Server to obtain
the location of the object(s) for a given inode and then communicates directly with an OSD to perform the final IO request.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/ocs/ceph101-cephfs.png" alt="Kernel Based CephFS Client">
</div>
<div class="title">Figure 35. File Access (Ceph Filesystem or CephFS)</div>
</div>
<div class="paragraph">
<p>CephFS is typically used for RWX claims but can also be used to support RWO claims.</p>
</div>
<div class="paragraph lead">
<p><strong><em>Object Storage, S3 and Swift (Ceph RADOS Gateway)</em></strong></p>
</div>
<div class="paragraph">
<p>This access method offers support for the Amazon S3 and OpenStack Swift support on top of a Ceph cluster. The Openshift Container Storage Multi Cloud
Gateway can leverage the RADOS Gateway to support Object Bucket Claims. From the Multi Cloud Gateway perspective the RADOS Gateway will be tagged
as a compatible S3 endpoint.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/ocs/ceph101-rgw.png" alt="S3 and Swift Support">
</div>
<div class="title">Figure 36. Amazone S3 or OpenStack Swift (Ceph RADOS Gateway)</div>
</div>
<div class="paragraph lead">
<p><strong>CRUSH</strong></p>
</div>
<div class="paragraph">
<p>The Ceph cluster being a distributed architecture some solution had to be designed to provide an efficient way to distribute the data across the multiple
OSDs in the cluster. The technique used is called CRUSH or Controlled Replication Under Scalable Hashing. With CRUSH, every object is assigned to one
and only one hash bucket known as a Placement Group (PG).</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/ocs/ceph101-crushfromobjecttoosd.png" alt="From Object to OSD">
</div>
</div>
<div class="paragraph">
<p>CRUSH is the central point of configuration for the topology of the cluster. It offers a pseudo-random placement algorithm to distribute the objects across
the PGs and uses rules to determine the mapping of the PGs to the OSDs. In essence, the PGs are an abstraction layer between the objects (application layer)
and the OSDs (physical layer). In case of failure, the PGs will be remapped to different physical devices (OSDs) and eventually see their content resynchronized
to match the protection rules  selected by the storage administrator.</p>
</div>
<div class="paragraph lead">
<p><strong>Cluster Partitioning</strong></p>
</div>
<div class="paragraph">
<p>The Ceph OSDs will be in charge of the protection of the data as well as the constant checking of the integrity of the data stored in the entire cluster.
The cluster will be separated into logical partitions, known as pools. Each pool has the following properties that can be adjusted:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>An ID (immutable)</p>
</li>
<li>
<p>A name</p>
</li>
<li>
<p>A number of PGs to distribute the objects across the OSDs</p>
</li>
<li>
<p>A CRUSH rule to determine the mapping of the PGs for this pool</p>
</li>
<li>
<p>A type of protection (Replication or Erasure Coding)</p>
</li>
<li>
<p>Parameters associated with the type of protection</p>
<div class="ulist">
<ul>
<li>
<p>Number of copies for replicated pools</p>
</li>
<li>
<p>K and M chunks for Erasure Coding</p>
</li>
</ul>
</div>
</li>
<li>
<p>Various flags to influence the behavior of the cluster</p>
</li>
</ul>
</div>
<div class="paragraph lead">
<p><strong>Pools and PGs</strong></p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/ocs/ceph101-thefullpicture.png" alt="From Object to OSD">
</div>
<div class="title">Figure 37. Pools and PGs</div>
</div>
<div class="paragraph">
<p>The diagram above shows the relationship end to end between the object at the access method level down to the OSDs at the physical layer.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph">
<p>A Ceph pool has no size and is able to consume the space available any OSD where its PGs are created. A Placement Group or PG belongs to only one pool.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph lead">
<p><strong>Data Protection</strong></p>
</div>
<div class="paragraph">
<p>Ceph supports two types of data protection presented in the diagram below.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/ocs/ceph101-dataprotection.png" alt="Replicated Pools vs Erasure Coded Pools">
</div>
<div class="title">Figure 38. Ceph Data Protection</div>
</div>
<div class="paragraph">
<p>Replicated pools provide better performance in almost all cases at the cost of a lower usable to raw storage ratio (1 usable byte is stored using 3 bytes of raw storage)
while <code>Erasure Coding</code> provides a cost efficient way to store data with less performance. Red Hat supports the following <code>Erasure Coding</code> profiles with their corresponding usable to raw ratio:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>4+2 (1:2 ratio)</p>
</li>
<li>
<p>8+3 (1:1.375 ratio)</p>
</li>
<li>
<p>8+4 (1:2 ratio)</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Another advantage of <code>Erasure Coding</code> (EC) is its ability to offer extreme resilience and durability as we can configure the number of parities being used.
EC can be used for the RADOS Gateway access method and for the RBD access method (performance impact).</p>
</div>
<div class="paragraph lead">
<p><strong>Data Distribution</strong></p>
</div>
<div class="paragraph">
<p>To leverage the Ceph architecture at its best, all access methods but librados, will access the data in the cluster through a collection of objects. Hence a 1GB
block device will be a collection of objects, each supporting a set of device sectors. Therefore, a 1GB file is stored in a CephFS directory will be split into multiple objects. Also a 5GB S3 object stored through the RADOS Gateway via the Multi Cloud Gateway will be divided in multiple objects.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="images/ocs/ceph101-rbdlayout.png" alt="RADOS Block Device Layout">
</div>
<div class="title">Figure 39. Data Distribution</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph">
<p>By default, each access method uses an object size of 4MB. The above diagram details how a 32MB RBD (Block Device) supporting a RWO PVC will be scattered throughout the cluster.</p>
</div>
</td>
</tr>
</table>
</div>
</div>
</div>
</div>
<div id="footer">
<div id="footer-text">
Last updated 2020-01-24 11:46:37 +0100
</div>
</div>
<style>
pre.pygments .hll { background-color: #ffffcc }
pre.pygments  { background: #f8f8f8; }
pre.pygments .tok-c { color: #408080; font-style: italic } /* Comment */
pre.pygments .tok-err { border: 1px solid #FF0000 } /* Error */
pre.pygments .tok-k { color: #008000; font-weight: bold } /* Keyword */
pre.pygments .tok-o { color: #666666 } /* Operator */
pre.pygments .tok-ch { color: #408080; font-style: italic } /* Comment.Hashbang */
pre.pygments .tok-cm { color: #408080; font-style: italic } /* Comment.Multiline */
pre.pygments .tok-cp { color: #BC7A00 } /* Comment.Preproc */
pre.pygments .tok-cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */
pre.pygments .tok-c1 { color: #408080; font-style: italic } /* Comment.Single */
pre.pygments .tok-cs { color: #408080; font-style: italic } /* Comment.Special */
pre.pygments .tok-gd { color: #A00000 } /* Generic.Deleted */
pre.pygments .tok-ge { font-style: italic } /* Generic.Emph */
pre.pygments .tok-gr { color: #FF0000 } /* Generic.Error */
pre.pygments .tok-gh { color: #000080; font-weight: bold } /* Generic.Heading */
pre.pygments .tok-gi { color: #00A000 } /* Generic.Inserted */
pre.pygments .tok-go { color: #888888 } /* Generic.Output */
pre.pygments .tok-gp { color: #000080; font-weight: bold } /* Generic.Prompt */
pre.pygments .tok-gs { font-weight: bold } /* Generic.Strong */
pre.pygments .tok-gu { color: #800080; font-weight: bold } /* Generic.Subheading */
pre.pygments .tok-gt { color: #0044DD } /* Generic.Traceback */
pre.pygments .tok-kc { color: #008000; font-weight: bold } /* Keyword.Constant */
pre.pygments .tok-kd { color: #008000; font-weight: bold } /* Keyword.Declaration */
pre.pygments .tok-kn { color: #008000; font-weight: bold } /* Keyword.Namespace */
pre.pygments .tok-kp { color: #008000 } /* Keyword.Pseudo */
pre.pygments .tok-kr { color: #008000; font-weight: bold } /* Keyword.Reserved */
pre.pygments .tok-kt { color: #B00040 } /* Keyword.Type */
pre.pygments .tok-m { color: #666666 } /* Literal.Number */
pre.pygments .tok-s { color: #BA2121 } /* Literal.String */
pre.pygments .tok-na { color: #7D9029 } /* Name.Attribute */
pre.pygments .tok-nb { color: #008000 } /* Name.Builtin */
pre.pygments .tok-nc { color: #0000FF; font-weight: bold } /* Name.Class */
pre.pygments .tok-no { color: #880000 } /* Name.Constant */
pre.pygments .tok-nd { color: #AA22FF } /* Name.Decorator */
pre.pygments .tok-ni { color: #999999; font-weight: bold } /* Name.Entity */
pre.pygments .tok-ne { color: #D2413A; font-weight: bold } /* Name.Exception */
pre.pygments .tok-nf { color: #0000FF } /* Name.Function */
pre.pygments .tok-nl { color: #A0A000 } /* Name.Label */
pre.pygments .tok-nn { color: #0000FF; font-weight: bold } /* Name.Namespace */
pre.pygments .tok-nt { color: #008000; font-weight: bold } /* Name.Tag */
pre.pygments .tok-nv { color: #19177C } /* Name.Variable */
pre.pygments .tok-ow { color: #AA22FF; font-weight: bold } /* Operator.Word */
pre.pygments .tok-w { color: #bbbbbb } /* Text.Whitespace */
pre.pygments .tok-mb { color: #666666 } /* Literal.Number.Bin */
pre.pygments .tok-mf { color: #666666 } /* Literal.Number.Float */
pre.pygments .tok-mh { color: #666666 } /* Literal.Number.Hex */
pre.pygments .tok-mi { color: #666666 } /* Literal.Number.Integer */
pre.pygments .tok-mo { color: #666666 } /* Literal.Number.Oct */
pre.pygments .tok-sa { color: #BA2121 } /* Literal.String.Affix */
pre.pygments .tok-sb { color: #BA2121 } /* Literal.String.Backtick */
pre.pygments .tok-sc { color: #BA2121 } /* Literal.String.Char */
pre.pygments .tok-dl { color: #BA2121 } /* Literal.String.Delimiter */
pre.pygments .tok-sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */
pre.pygments .tok-s2 { color: #BA2121 } /* Literal.String.Double */
pre.pygments .tok-se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */
pre.pygments .tok-sh { color: #BA2121 } /* Literal.String.Heredoc */
pre.pygments .tok-si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */
pre.pygments .tok-sx { color: #008000 } /* Literal.String.Other */
pre.pygments .tok-sr { color: #BB6688 } /* Literal.String.Regex */
pre.pygments .tok-s1 { color: #BA2121 } /* Literal.String.Single */
pre.pygments .tok-ss { color: #19177C } /* Literal.String.Symbol */
pre.pygments .tok-bp { color: #008000 } /* Name.Builtin.Pseudo */
pre.pygments .tok-fm { color: #0000FF } /* Name.Function.Magic */
pre.pygments .tok-vc { color: #19177C } /* Name.Variable.Class */
pre.pygments .tok-vg { color: #19177C } /* Name.Variable.Global */
pre.pygments .tok-vi { color: #19177C } /* Name.Variable.Instance */
pre.pygments .tok-vm { color: #19177C } /* Name.Variable.Magic */
pre.pygments .tok-il { color: #666666 } /* Literal.Number.Integer.Long */
</style>
</body>
</html>