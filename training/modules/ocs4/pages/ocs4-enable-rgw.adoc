= Enable the RGW on an OCS internal deployment

Depending on the infrastructuire where you deploy OCS, the RGW may or may not be deployed. Typically, it is not deployed in Cloud environments. +
The following steps will show you how to do this deployment manually.

== Status verification

First, make sure that the RGW is not already deployed. You can do this with the following command:

[source, execute]
----
oc get -n openshift-storage CephObjectStore
----

This should return nothing. Otherwise you already have an ObjectStore, and therefore an active RGW. In this case you can directly go to the Service and Route steps to gain access to it.

== Creating the CephObjectStore

The CephObjectStore can be deployed with this YAML file (`oc apply -f cephobjectstore.yaml`):

.cephobjectstore.yaml
[source, yaml]
----
---
apiVersion: ceph.rook.io/v1
kind: CephObjectStore
metadata:
  name: s3a
  namespace: openshift-storage
spec:
  dataPool:
    crushRoot: ""
    deviceClass: ""
    erasureCoded:
      algorithm: ""
      codingChunks: 0
      dataChunks: 0
    failureDomain: zone
    replicated:
      size: 3
  gateway:
    allNodes: false
    instances: 1
    placement:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchExpressions:
            - key: cluster.ocs.openshift.io/openshift-storage
              operator: Exists
      podAntiAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - podAffinityTerm:
            labelSelector:
              matchExpressions:
              - key: app
                operator: In
                values:
                - rook-ceph-rgw
            topologyKey: kubernetes.io/hostname
          weight: 100
      tolerations:
      - effect: NoSchedule
        key: node.ocs.openshift.io/storage
        operator: Equal
        value: "true"
    port: 80
    resources:
      limits:
        cpu: "2"
        memory: 4Gi
      requests:
        cpu: "1"
        memory: 4Gi
    securePort: 0
    sslCertificateRef: ""
  metadataPool:
    crushRoot: ""
    deviceClass: ""
    erasureCoded:
      algorithm: ""
      codingChunks: 0
      dataChunks: 0
    failureDomain: zone
    replicated:
      size: 3
----

_Note_: the parameters you may want to change are:

- `name`: you can change it but make sure to adapt the other files that follow.
- `failureDomain`: default is `zone` for AWS. You may want to adapt for other infrastructures.
- `instances`: if you want more than one RGW. In this case, make sure to put some load-balancing in front.

== Create the Service and the Route

To access the RGW, you'll need of course at least a Service (for access within the OCP cluster), and a Route if you want to access it from anywhere. So you can apply one or both of those files:

.service.yaml
[source, yaml]
----
---
kind: Service
apiVersion: v1
metadata:
  name: rook-ceph-rgw-ocs-storagecluster-cephobjectstore
  namespace: openshift-storage
  labels:
    app: rook-ceph-rgw
    ceph_daemon_id: s3a
    rgw: s3a
    rook_cluster: openshift-storage
    rook_object_store: s3a
spec:
  ports:
    - name: http
      protocol: TCP
      port: 80
      targetPort: 80
  selector:
    app: rook-ceph-rgw
    ceph_daemon_id: s3a
    rgw: s3a
    rook_cluster: openshift-storage
    rook_object_store: s3a
  type: ClusterIP
  sessionAffinity: None
----

.route.yaml
[source, yaml]
----
---
kind: Route
apiVersion: route.openshift.io/v1
metadata:
  name: rgw
  namespace: openshift-storage
  labels:
    app: rook-ceph-rgw
    ceph_daemon_id: s3a
    rgw: s3a
    rook_cluster: openshift-storage
    rook_object_store: s3a
spec:
  to:
    kind: Service
    name: rook-ceph-rgw-s3a
    weight: 100
  port:
    targetPort: http
  wildcardPolicy: None
----

The Service or the Route you have created are the endpoints that you can use in your application or code that connects to Object Storage.

== Ceph toolbox

As the Ceph dashboard is not available with OCS for an internal deployment, you have to interact direcly with the RGW to create S3 users who will then be able to connect using the S3 API (through s3cmd, boto3 library, any S3-compatible tool...). +

To create a user you can directly query the Ceph API, or use radosgw-admin. The easiest way to do that is to deploy the Ceph toolbox. This is easily done with this command: 

[source, execute]
----
 oc patch OCSInitialization ocsinit -n openshift-storage --type json --patch  '[{ "op": "replace", "path": "/spec/enableCephTools", "value": true }]'
----

== Create a S3 user

=== Method 1
To create a new S3 user interactively, you can log into the Ceph toolbox like this (or go to the Terminal tab of the toolbox pod in the OCP UI):

[source, execute]
----
oc rsh -n openshift-storage `oc get pods -n openshift-storage | grep rook-ceph-tools | grep Running | awk '{print $1}'`
----
and then create the user with:
[source, execute]
----
radosgw-admin user create --display-name="Your user" --uid=your-user
----

The output of the command will give you all the details for the newly create user, especially this part:

[source, json]
----
{
  "user": "your-user",
  "access_key": "XXXXXXXXXXXXXXXX",
  "secret_key": "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX"
}
----

=== Method 2

To be honest, it's the same as the previous one, but in one line...
[source, execute]
----
oc exec -n openshift-storage `oc get pods -n openshift-storage | grep rook-ceph-tools | grep Running | awk '{print $1}'` -- radosgw-admin user create --uid="<user-name>" --display-name="<Display Name>"
----

